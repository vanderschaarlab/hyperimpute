{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb18e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw_diab, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw_breast_cancer, _ = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_raw_california, _ = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_raw_iris, y_raw_iris = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "climate_model_samples = np.loadtxt(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat\",\n",
    "    skiprows=1,\n",
    ")\n",
    "climate_model_df = pd.DataFrame(climate_model_samples)\n",
    "\n",
    "raw_datasets = {\n",
    "    \"iris\": X_raw_iris,\n",
    "    \"parkinsons\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",\n",
    "        sep=\",\",\n",
    "    ),\n",
    "    \"ionosphere\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"credit\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"blood\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\"\n",
    "    ),\n",
    "    \"airfoil\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "        header=None,\n",
    "        sep=\"\\\\t\",\n",
    "    ),\n",
    "    \"wine_red\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"spam\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "    ),\n",
    "    \"wine_white\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"letter\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "        header=None,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in raw_datasets:\n",
    "    print(df, len(raw_datasets[df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79bf46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_imputation import simulate_scenarios\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "import hyperimpute.logger as log\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6609076",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Model insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5900ca8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from benchmark_imputation import ws_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "dispatcher = Parallel(n_jobs=2)\n",
    "\n",
    "\n",
    "def get_imputer():\n",
    "    return imputers.get(\n",
    "        \"hyperimpute\",\n",
    "        optimizer=\"hyperband\",\n",
    "        select_lazy=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_model_trace_for_dataset(\n",
    "    name: str,\n",
    "    X_raw: pd.DataFrame,\n",
    "    scenarios: list = [\"MAR\", \"MCAR\", \"MNAR\"],\n",
    "    miss_pct: list = [0.1, 0.3, 0.5, 0.7],\n",
    "    debug: bool = True,\n",
    "):\n",
    "    imputation_scenarios = simulate_scenarios(\n",
    "        X_raw, column_limit=10, sample_columns=False\n",
    "    )\n",
    "    traces = {}\n",
    "\n",
    "    def _local_eval(scenario, missingness):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        x, x_miss, mask = imputation_scenarios[scenario][missingness]\n",
    "        print(\"  evaluate \", name, scenario, missingness)\n",
    "        try:\n",
    "            model = get_imputer()\n",
    "            model.fit_transform(x_miss.copy())\n",
    "\n",
    "            return model.trace()[\"models\"]\n",
    "\n",
    "        except BaseException as e:\n",
    "            print(\"scenario failed\", str(e))\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        traces[scenario] = {}\n",
    "\n",
    "        local_traces = dispatcher(\n",
    "            delayed(_local_eval)(scenario, miss) for miss in miss_pct\n",
    "        )\n",
    "\n",
    "        for local_trace, miss in zip(local_traces, miss_pct):\n",
    "            x, x_miss, mask = imputation_scenarios[scenario][miss]\n",
    "            observed_x = x_miss[~x_miss.isnull().any(axis=1)]\n",
    "            traces[scenario][miss] = {\n",
    "                \"model_trace\": local_trace,\n",
    "                \"observed_rows\": len(observed_x),\n",
    "            }\n",
    "\n",
    "    return traces\n",
    "\n",
    "\n",
    "def evaluate_dataset(dataset, seed: int = 0):\n",
    "    enable_reproducible_results(seed)\n",
    "\n",
    "    start = time()\n",
    "    df = raw_datasets[dataset]\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "    model_trace = evaluate_model_trace_for_dataset(dataset, df)\n",
    "\n",
    "    print(f\"      evaluation for {dataset} took {time() - start}\")\n",
    "    return model_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c40f36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "full_output = {}\n",
    "for dataset in raw_datasets:\n",
    "    print(\"eval dataset\", dataset)\n",
    "    try:\n",
    "        full_output[dataset] = evaluate_dataset(dataset)\n",
    "    except BaseException as e:\n",
    "        print(\"scenario failed\", dataset, e)\n",
    "        continue\n",
    "\n",
    "    with open(\"general_results/model_selection_trace.json\", \"w\") as f:\n",
    "        json.dump(full_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abfb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"general_results/model_selection_trace.json\", \"w\") as f:\n",
    "    json.dump(full_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34479021",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741764c",
   "metadata": {},
   "source": [
    "## By miss ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e914303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "with open(\"general_results/model_selection_trace.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "output_dir = Path(\"diagrams/model_selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e85e47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def normalize_model_name(name):\n",
    "    return {\n",
    "        \"linear_regression\": \"linear models\",\n",
    "        \"logistic_regression\": \"linear models\",\n",
    "        \"xgboost\": \"gradient boosting\",\n",
    "        \"xgboost_regressor\": \"gradient boosting\",\n",
    "        \"catboost\": \"gradient boosting\",\n",
    "        \"catboost_regressor\": \"gradient boosting\",\n",
    "        \"random_forest_regressor\": \"random forests\",\n",
    "        \"random_forest\": \"random forests\",\n",
    "        \"neural_nets_regression\": \"neural nets\",\n",
    "        \"neural_nets\": \"neural nets\",\n",
    "    }[name]\n",
    "\n",
    "\n",
    "def filter_models(models, col_type):\n",
    "    filtered = []\n",
    "\n",
    "    def is_clf(model):\n",
    "        return (\"regr\" not in model) or model == \"logistic_regression\"\n",
    "\n",
    "    def is_reg(model):\n",
    "        return (\"regr\" in model) and model != \"logistic_regression\"\n",
    "\n",
    "    for mod in models:\n",
    "        if (\n",
    "            (col_type == \"continuous\" and is_reg(mod))\n",
    "            or (col_type == \"categorical\" and is_clf(mod))\n",
    "            or col_type == \"all\"\n",
    "        ):\n",
    "            filtered.append(mod)\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def compress_model_trace(trace, col_type):\n",
    "    all_models = []\n",
    "\n",
    "    for col in trace:\n",
    "        local_models = np.unique(trace[col]).tolist()\n",
    "        all_models.extend(filter_models(local_models, col_type))\n",
    "\n",
    "    raw_models = np.unique(all_models).tolist()\n",
    "    models = []\n",
    "    for mod in raw_models:\n",
    "        models.append(normalize_model_name(mod))\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def generate_normalized_model_count(data, scenario, col_type):\n",
    "    model_tracking = {}\n",
    "    for data_set in data:\n",
    "        for missingness in [\"0.1\", \"0.3\", \"0.5\", \"0.7\"]:\n",
    "            trace = data[data_set][scenario][missingness]\n",
    "            models_selected = compress_model_trace(trace[\"model_trace\"], col_type)\n",
    "\n",
    "            for model in models_selected:\n",
    "                if not model_tracking.get(missingness, {}).get(model, {}):\n",
    "                    if not model_tracking.get(missingness, {}):\n",
    "                        model_tracking[missingness] = {model: 1}\n",
    "                    else:\n",
    "                        model_tracking[missingness][model] = 1\n",
    "                else:\n",
    "                    model_tracking[missingness][model] += 1\n",
    "\n",
    "    unique_models = []\n",
    "    for missingness in model_tracking:\n",
    "        models = list(model_tracking[missingness].keys())\n",
    "        for model in models:\n",
    "            if model not in unique_models:\n",
    "                unique_models.append(model)\n",
    "\n",
    "    normalized_model_count = {}\n",
    "    total_model_count = sum([count for model, count in model_tracking[\"0.1\"].items()])\n",
    "    for model in unique_models:\n",
    "        normalized_model_count[model] = [0, 0, 0, 0]\n",
    "        for index, missingness in enumerate(model_tracking):\n",
    "            try:\n",
    "                normalized_model_count[model][index] = (\n",
    "                    model_tracking[missingness][model] / total_model_count\n",
    "                )\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    return normalized_model_count\n",
    "\n",
    "\n",
    "def plot_figure(normalized_model_count, scenario, col_type):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    missingness_rates = [0.1, 0.3, 0.5, 0.7]\n",
    "    for model in normalized_model_count:\n",
    "        plt.plot(\n",
    "            missingness_rates,\n",
    "            normalized_model_count[model],\n",
    "            label=model,\n",
    "            marker=\"o\",\n",
    "            ms=8,\n",
    "            alpha=0.75,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Missingness Rate\", fontsize=20)\n",
    "    plt.ylabel(\"Selection Probability\", fontsize=20)\n",
    "    plt.xticks([0.1, 0.3, 0.5, 0.7], fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.legend(prop={\"size\": 12}, loc=2)\n",
    "\n",
    "    plt.savefig(output_dir / f\"model_selection_by_miss_cnt_{scenario}_{col_type}.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for col_type in [\"all\", \"categorical\", \"continuous\"]:\n",
    "        print(\"scenario\", scenario, col_type)\n",
    "        normalized_model_count = generate_normalized_model_count(\n",
    "            data, scenario, col_type\n",
    "        )\n",
    "        plot_figure(normalized_model_count, scenario, col_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697960a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_normalized_model_count(data, scenario, col_type):\n",
    "    model_tracking = {}\n",
    "    for data_set in data:\n",
    "        for missingness in [\"0.1\", \"0.3\", \"0.5\", \"0.7\"]:\n",
    "            trace = data[data_set][scenario][missingness]\n",
    "            models_selected = compress_model_trace(trace[\"model_trace\"], col_type)\n",
    "\n",
    "            for model in models_selected:\n",
    "                if not model_tracking.get(missingness, {}).get(model, {}):\n",
    "                    if not model_tracking.get(missingness, {}):\n",
    "                        model_tracking[missingness] = {model: 1}\n",
    "                    else:\n",
    "                        model_tracking[missingness][model] = 1\n",
    "                else:\n",
    "                    model_tracking[missingness][model] += 1\n",
    "\n",
    "    unique_models = []\n",
    "    for missingness in model_tracking:\n",
    "        models = list(model_tracking[missingness].keys())\n",
    "        for model in models:\n",
    "            if model not in unique_models:\n",
    "                unique_models.append(model)\n",
    "\n",
    "    normalized_model_count = {}\n",
    "    for model in unique_models:\n",
    "        normalized_model_count[model] = [0, 0, 0, 0]\n",
    "        for index, missingness in enumerate(model_tracking):\n",
    "            total_model_count = sum(\n",
    "                [count for model, count in model_tracking[missingness].items()]\n",
    "            )\n",
    "            try:\n",
    "                normalized_model_count[model][index] = (\n",
    "                    model_tracking[missingness][model] / total_model_count\n",
    "                )\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    return normalized_model_count\n",
    "\n",
    "\n",
    "def plot_figure(normalized_model_count, scenario, col_type):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    missingness_rates = [0.1, 0.3, 0.5, 0.7]\n",
    "    bottom = np.zeros(4)\n",
    "    for index, model in enumerate(normalized_model_count):\n",
    "        plt.bar(\n",
    "            missingness_rates,\n",
    "            normalized_model_count[model],\n",
    "            width=0.1,\n",
    "            label=model,\n",
    "            alpha=0.8,\n",
    "            bottom=bottom,\n",
    "        )\n",
    "        bottom += np.array(normalized_model_count[model])\n",
    "    plt.xlabel(\"Missingness Rate\", fontsize=20)\n",
    "    plt.ylabel(\"Selection Probability\", fontsize=20)\n",
    "    plt.xticks([0.1, 0.3, 0.5, 0.7], fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "\n",
    "    plt.legend(\n",
    "        prop={\"size\": 14},\n",
    "        ncol=2,\n",
    "        shadow=\"True\",\n",
    "        loc=\"center\",\n",
    "        bbox_to_anchor=(0, 1.05, 1.05, 0),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        output_dir / f\"model_selection_by_miss_cnt_{scenario}_{col_type}_barplot.png\"\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for col_type in [\"all\", \"categorical\", \"continuous\"]:\n",
    "        print(\"scenario\", scenario, col_type)\n",
    "        normalized_model_count = generate_normalized_model_count(\n",
    "            data, scenario, col_type\n",
    "        )\n",
    "        plot_figure(normalized_model_count, scenario, col_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176595e9",
   "metadata": {},
   "source": [
    "## By observed data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86563876",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "buckets = [100, 500, 1000, 2000, 5000, 10000, 20000]\n",
    "\n",
    "\n",
    "def get_size_bucket(df_size):\n",
    "    for thresh in buckets:\n",
    "        if df_size - 1 < thresh:\n",
    "            return f\"< {thresh}\"\n",
    "    raise RuntimeError(f\"unsupported {df_size}\")\n",
    "\n",
    "\n",
    "def generate_model_to_availability_count(data, scenario, col_type):\n",
    "    model_tracking = {}\n",
    "    for data_set in data:\n",
    "        raw_df = raw_datasets[data_set]\n",
    "        df_len = len(raw_df)\n",
    "        for miss_pct in [0.1, 0.3, 0.5, 0.7]:\n",
    "            missingness = str(miss_pct)\n",
    "            trace = data[data_set][scenario][missingness]\n",
    "            observed_data = int((1 - miss_pct) * df_len)\n",
    "            models_selected = compress_model_trace(trace[\"model_trace\"], col_type)\n",
    "\n",
    "            bucket = get_size_bucket(observed_data)\n",
    "\n",
    "            for model in models_selected:\n",
    "                if not model_tracking.get(bucket, {}).get(model, {}):\n",
    "                    if not model_tracking.get(bucket, {}):\n",
    "                        model_tracking[bucket] = {model: 1}\n",
    "                    else:\n",
    "                        model_tracking[bucket][model] = 1\n",
    "                else:\n",
    "                    model_tracking[bucket][model] += 1\n",
    "\n",
    "    unique_models = []\n",
    "    for bucket in model_tracking:\n",
    "        models = list(model_tracking[bucket].keys())\n",
    "        for model in models:\n",
    "            if model not in unique_models:\n",
    "                unique_models.append(model)\n",
    "\n",
    "    normalized_model_count = {}\n",
    "\n",
    "    first_key = list(model_tracking.keys())[0]\n",
    "    total_model_count = sum(\n",
    "        [count for model, count in model_tracking[first_key].items()]\n",
    "    )\n",
    "    for model in unique_models:\n",
    "        normalized_model_count[model] = [0] * len(buckets)\n",
    "        for index, bucket in enumerate(model_tracking):\n",
    "            try:\n",
    "                normalized_model_count[model][index] = (\n",
    "                    model_tracking[bucket][model] / total_model_count\n",
    "                )\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    return normalized_model_count\n",
    "\n",
    "\n",
    "def plot_figure(normalized_model_count, scenario, col_type):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    for model in normalized_model_count:\n",
    "        plt.plot(\n",
    "            [get_size_bucket(bucket) for bucket in buckets],\n",
    "            normalized_model_count[model],\n",
    "            label=model,\n",
    "            marker=\"o\",\n",
    "            ms=8,\n",
    "            alpha=0.75,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Observed data size\", fontsize=20)\n",
    "    plt.ylabel(\"Selection Probability\", fontsize=20)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.legend(prop={\"size\": 12}, loc=2)\n",
    "\n",
    "    plt.savefig(\n",
    "        output_dir / f\"model_selection_by_data_availability_{scenario}_{col_type}.png\"\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for col_type in [\"all\", \"categorical\", \"continuous\"]:\n",
    "        print(\"scenario\", scenario, col_type)\n",
    "        out = generate_model_to_availability_count(data, scenario, col_type)\n",
    "        plot_figure(out, scenario, col_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6893771f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_model_to_availability_count(data, scenario, col_type):\n",
    "    model_tracking = {}\n",
    "    for data_set in data:\n",
    "        raw_df = raw_datasets[data_set]\n",
    "        df_len = len(raw_df)\n",
    "        for miss_pct in [0.1, 0.3, 0.5, 0.7]:\n",
    "            missingness = str(miss_pct)\n",
    "            trace = data[data_set][scenario][missingness]\n",
    "            observed_data = int((1 - miss_pct) * df_len)\n",
    "            models_selected = compress_model_trace(trace[\"model_trace\"], col_type)\n",
    "\n",
    "            bucket = get_size_bucket(observed_data)\n",
    "\n",
    "            for model in models_selected:\n",
    "                if not model_tracking.get(bucket, {}).get(model, {}):\n",
    "                    if not model_tracking.get(bucket, {}):\n",
    "                        model_tracking[bucket] = {model: 1}\n",
    "                    else:\n",
    "                        model_tracking[bucket][model] = 1\n",
    "                else:\n",
    "                    model_tracking[bucket][model] += 1\n",
    "\n",
    "    unique_models = []\n",
    "    for bucket in model_tracking:\n",
    "        models = list(model_tracking[bucket].keys())\n",
    "        for model in models:\n",
    "            if model not in unique_models:\n",
    "                unique_models.append(model)\n",
    "\n",
    "    normalized_model_count = {}\n",
    "    for model in unique_models:\n",
    "        normalized_model_count[model] = [0] * len(buckets)\n",
    "        for index, bucket in enumerate(model_tracking):\n",
    "            total_model_count = sum(\n",
    "                [count for model, count in model_tracking[bucket].items()]\n",
    "            )\n",
    "            try:\n",
    "                normalized_model_count[model][index] = (\n",
    "                    model_tracking[bucket][model] / total_model_count\n",
    "                )\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    return normalized_model_count\n",
    "\n",
    "\n",
    "def plot_figure(normalized_model_count, scenario, col_type):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    bottom = np.zeros(len(buckets))\n",
    "    for model in normalized_model_count:\n",
    "        plt.bar(\n",
    "            [get_size_bucket(bucket) for bucket in buckets],\n",
    "            normalized_model_count[model],\n",
    "            width=0.7,\n",
    "            label=model,\n",
    "            alpha=0.8,\n",
    "            bottom=bottom,\n",
    "        )\n",
    "        bottom += np.array(normalized_model_count[model])\n",
    "\n",
    "    plt.xlabel(\"Observed data size\", fontsize=20)\n",
    "    plt.ylabel(\"Selection Probability\", fontsize=20)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.legend(\n",
    "        prop={\"size\": 14},\n",
    "        ncol=2,\n",
    "        shadow=\"True\",\n",
    "        loc=\"center\",\n",
    "        bbox_to_anchor=(0, 1.05, 1.05, 0),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        output_dir\n",
    "        / f\"model_selection_by_data_availability_{scenario}_{col_type}_barplot.png\"\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for col_type in [\"all\", \"categorical\", \"continuous\"]:\n",
    "        print(\"scenario\", scenario, col_type)\n",
    "        out = generate_model_to_availability_count(data, scenario, col_type)\n",
    "        plot_figure(out, scenario, col_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2eb90c",
   "metadata": {},
   "source": [
    "## Plot by iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d8342",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_model_by_iteration(data, scenario, col_type):\n",
    "    iteration_tracking = {\n",
    "        \"linear models\": [0] * 100,\n",
    "        \"gradient boosting\": [0] * 100,\n",
    "        \"neural nets\": [0] * 100,\n",
    "        \"random forests\": [0] * 100,\n",
    "    }\n",
    "\n",
    "    for data_set in data:\n",
    "        for miss_pct in data[data_set][scenario]:\n",
    "            missingness = str(miss_pct)\n",
    "            trace = data[data_set][scenario][missingness]\n",
    "            models_selected = trace[\"model_trace\"]\n",
    "            for col in models_selected:\n",
    "                filtered = filter_models(models_selected[col], col_type)\n",
    "                for it, model in enumerate(filtered):\n",
    "                    iteration_tracking[normalize_model_name(model)][it] += 1\n",
    "\n",
    "    max_iter = 0\n",
    "    for it in range(100):\n",
    "        total_models = 0\n",
    "        for model_class in iteration_tracking:\n",
    "            total_models += iteration_tracking[model_class][it]\n",
    "        if total_models == 0:\n",
    "            max_iter = it\n",
    "            break\n",
    "\n",
    "        for model_class in iteration_tracking:\n",
    "            iteration_tracking[model_class][it] /= total_models\n",
    "\n",
    "    for model_class in iteration_tracking:\n",
    "        iteration_tracking[model_class] = iteration_tracking[model_class][:max_iter]\n",
    "\n",
    "    return iteration_tracking\n",
    "\n",
    "\n",
    "def plot_figure(normalized_model_count, scenario, col_type):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    for model in normalized_model_count:\n",
    "        plt.plot(\n",
    "            range(len(normalized_model_count[model])),\n",
    "            normalized_model_count[model],\n",
    "            label=model,\n",
    "            marker=\"o\",\n",
    "            ms=8,\n",
    "            alpha=0.75,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Iteration\", fontsize=20)\n",
    "    plt.ylabel(\"Selection Probability\", fontsize=20)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.legend(prop={\"size\": 12}, loc=2)\n",
    "\n",
    "    plt.savefig(output_dir / f\"model_selection_by_iteration_{scenario}_{col_type}.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for col_type in [\"all\", \"categorical\", \"continuous\"]:\n",
    "        print(\"scenario\", scenario, col_type)\n",
    "        out = generate_model_by_iteration(data, scenario, col_type)\n",
    "        plot_figure(out, scenario, col_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfcd479",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_model_by_iteration(data, scenario, col_type):\n",
    "    iteration_tracking = {\n",
    "        \"linear models\": [0] * 100,\n",
    "        \"gradient boosting\": [0] * 100,\n",
    "        \"neural nets\": [0] * 100,\n",
    "        \"random forests\": [0] * 100,\n",
    "    }\n",
    "\n",
    "    for data_set in data:\n",
    "        for miss_pct in data[data_set][scenario]:\n",
    "            missingness = str(miss_pct)\n",
    "            trace = data[data_set][scenario][missingness]\n",
    "            models_selected = trace[\"model_trace\"]\n",
    "            for col in models_selected:\n",
    "                filtered = filter_models(models_selected[col], col_type)\n",
    "                for it, model in enumerate(models_selected[col]):\n",
    "                    iteration_tracking[normalize_model_name(model)][it] += 1\n",
    "\n",
    "    max_iter = 0\n",
    "    for it in range(100):\n",
    "        total_models = 0\n",
    "        for model_class in iteration_tracking:\n",
    "            total_models += iteration_tracking[model_class][it]\n",
    "        if total_models == 0:\n",
    "            max_iter = it\n",
    "            break\n",
    "\n",
    "        for model_class in iteration_tracking:\n",
    "            iteration_tracking[model_class][it] /= total_models\n",
    "\n",
    "    for model_class in iteration_tracking:\n",
    "        iteration_tracking[model_class] = iteration_tracking[model_class][:max_iter]\n",
    "\n",
    "    return iteration_tracking\n",
    "\n",
    "\n",
    "def plot_figure(normalized_model_count, scenario, col_type):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    bottom = np.zeros(len(normalized_model_count[\"linear models\"]) - 1)\n",
    "    for model in normalized_model_count:\n",
    "        plt.bar(\n",
    "            range(len(normalized_model_count[model]) - 1),\n",
    "            normalized_model_count[model][:-1],\n",
    "            width=1,\n",
    "            label=model,\n",
    "            alpha=0.8,\n",
    "            bottom=bottom,\n",
    "        )\n",
    "        bottom += np.array(normalized_model_count[model][:-1])\n",
    "\n",
    "    plt.xlabel(\"Iteration\", fontsize=20)\n",
    "    plt.ylabel(\"Selection Probability\", fontsize=20)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.legend(\n",
    "        prop={\"size\": 14},\n",
    "        ncol=2,\n",
    "        shadow=\"True\",\n",
    "        loc=\"center\",\n",
    "        bbox_to_anchor=(0, 1.05, 1.05, 0),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        output_dir / f\"model_selection_by_iteration_{scenario}_{col_type}_barplot.png\"\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for col_type in [\"all\", \"categorical\", \"continuous\"]:\n",
    "        print(\"scenario\", scenario, col_type)\n",
    "        out = generate_model_by_iteration(data, scenario, col_type)\n",
    "        plot_figure(out, scenario, col_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec80be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f51c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
