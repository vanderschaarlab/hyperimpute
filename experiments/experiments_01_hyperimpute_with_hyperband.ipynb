{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "import hyperimpute.logger as log\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "enable_reproducible_results()\n",
    "\n",
    "imputers = Imputers()\n",
    "log.add(sink=sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "experiment = \"experiments_01_hyperimpute_with_hyperband\"\n",
    "\n",
    "\n",
    "def get_imputer():\n",
    "    return imputers.get(\"hyperimpute\", optimizer=\"hyperband\")\n",
    "\n",
    "\n",
    "def save_results(fname, results):\n",
    "    path = Path(experiment)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out = path / fname\n",
    "\n",
    "    with open(out, \"w\") as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "\n",
    "def evaluate_dataset_repeated(\n",
    "    name,\n",
    "    X_raw,\n",
    "    y,\n",
    "    ref_methods=[\n",
    "        \"mean\",\n",
    "        \"sklearn_ice\",\n",
    "        \"sklearn_missforest\",\n",
    "        \"softimpute\",\n",
    "        \"gain\",\n",
    "        \"sinkhorn\",\n",
    "    ],\n",
    "    scenarios=[\"MAR\", \"MCAR\", \"MNAR\"],\n",
    "    miss_pct=[0.1, 0.3, 0.5, 0.7],\n",
    "    n_iter=10,\n",
    "):\n",
    "    results = compare_models(\n",
    "        name=name,\n",
    "        evaluated_model=get_imputer(),\n",
    "        X_raw=X_raw,\n",
    "        ref_methods=ref_methods,\n",
    "        scenarios=scenarios,\n",
    "        miss_pct=miss_pct,\n",
    "        n_iter=n_iter,\n",
    "    )\n",
    "\n",
    "    save_results(name, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check in  debug mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "y = df[5]\n",
    "X_raw = df.drop(columns=[5])\n",
    "\n",
    "evaluate_dataset_repeated(\n",
    "    \"airfoil_debug\",\n",
    "    X_raw,\n",
    "    y,\n",
    "    scenarios=[\"MAR\"],\n",
    "    ref_methods=[\"mean\", \"ice\"],\n",
    "    n_iter=3,\n",
    "    miss_pct=[0.3],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperimpute.logger as log\n",
    "\n",
    "log.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset     | Length | Features |\n",
    "|-------------|--------|----------|\n",
    "| airfoil     | 1503   | 6        |\n",
    "| blood       | 748    | 5        |\n",
    "| bc          | 569    | 30       |\n",
    "| california  | 20640  | 8        |\n",
    "| climate     | 540    | 21       |\n",
    "| compression | 1030   | 9        |\n",
    "| slump       | 103    | 11       |\n",
    "| sonar       | 208    | 61       |\n",
    "| diabetes    | 442    | 10       |\n",
    "| wine_red    | 1599   | 12       |\n",
    "| wine_white  | 4898   | 12       |\n",
    "| yeast       | 1484   | 10       |\n",
    "| iris        | 150    | 4        |\n",
    "| libras      | 360    | 91       |\n",
    "| parkinsons  | 195    | 24       |\n",
    "| yacht       | 308    | 7        |\n",
    "| ionosphere  | 351    | 35       |\n",
    "| letter      | 20000  | 17       |\n",
    "| spam        | 4600   | 58       |\n",
    "| credit      | 690    | 16       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: UCI Airfoil Self-Noise Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/airfoil+self-noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"airfoil\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Breast Cancer Wisconsin (Diagnostic)\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X_raw, y = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"bc\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Compressive Strength Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/concrete+compressive+strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"compression\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine-Red dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality Data Set\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "\n",
    "y = df[last_col]\n",
    "mapped_labels = sorted(y.unique())\n",
    "mapping = {}\n",
    "for idx, label in enumerate(mapped_labels):\n",
    "    mapping[label] = idx\n",
    "y = y.map(mapping)\n",
    "\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"wine_red\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine-White dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "\n",
    "y = df[last_col]\n",
    "mapped_labels = sorted(y.unique())\n",
    "mapping = {}\n",
    "for idx, label in enumerate(mapped_labels):\n",
    "    mapping[label] = idx\n",
    "y = y.map(mapping)\n",
    "\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"wine_white\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeast Data Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\",\n",
    "    sep=\"\\s+\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "df = df.drop(columns=[0])\n",
    "\n",
    "for col in [9]:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"yeast\", X_raw, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"diabetes\", X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"iris\", X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"ionosphere\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"libras\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",\n",
    "    sep=\",\",\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "df = df.drop(columns=[\"name\"])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"parkinsons\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"spam\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"letter\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"credit\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def smooth_line(src: list) -> list:\n",
    "    return signal.savgol_filter(src, 3, 1)\n",
    "\n",
    "\n",
    "X_raw_diab, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw_breast_cancer, _ = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_raw_california, _ = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_raw_iris, y_raw_iris = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "climate_model_samples = np.loadtxt(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat\",\n",
    "    skiprows=1,\n",
    ")\n",
    "climate_model_df = pd.DataFrame(climate_model_samples)\n",
    "\n",
    "raw_datasets = {\n",
    "    \"airfoil\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "        header=None,\n",
    "        sep=\"\\\\t\",\n",
    "    ),\n",
    "    \"blood\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\"\n",
    "    ),\n",
    "    \"bc\": X_raw_breast_cancer,\n",
    "    \"california\": X_raw_california,\n",
    "    \"climate\": climate_model_df,\n",
    "    \"compression\": pd.read_excel(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    "    ),\n",
    "    \"slump\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\"\n",
    "    ),\n",
    "    \"sonar\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"diabetes\": X_raw_diab,\n",
    "    \"wine_red\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"wine_white\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"iris\": X_raw_iris,\n",
    "    \"libras\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"parkinsons\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",\n",
    "        sep=\",\",\n",
    "    ),\n",
    "    \"yacht\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data\",\n",
    "        sep=\"\\s+\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"ionosphere\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"letter\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"spam\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "    ),\n",
    "    \"credit\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\",\n",
    "        header=None,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse results\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "experiment = \"experiments_01_hyperimpute_with_hyperband\"\n",
    "results = Path(experiment).glob(\"*\")\n",
    "\n",
    "remap_models = {\n",
    "    \"Our method\": \"hyperimpute\",\n",
    "    \"sklearn_missforest\": \"missforest\",\n",
    "    \"sklearn_ice\": \"ice\",\n",
    "}\n",
    "norm_cols = [\n",
    "    \"Our method\",\n",
    "    \"mean\",\n",
    "    \"sklearn_missforest\",\n",
    "    \"sklearn_ice\",\n",
    "    \"gain\",\n",
    "    \"sinkhorn\",\n",
    "    \"softimpute\",\n",
    "]\n",
    "\n",
    "rmse_key = \"Mean RMSE\"\n",
    "wass_key = \"Mean Wasserstein distance\"\n",
    "pred_key = \"Mean downstream prediction error\"\n",
    "\n",
    "data = {}\n",
    "\n",
    "df_names = [\n",
    "    \"airfoil\",\n",
    "    \"bc\",\n",
    "    \"compression\",\n",
    "    \"diabetes\",\n",
    "    \"ionosphere\",\n",
    "    \"iris\",\n",
    "    \"libras\",\n",
    "    \"letter\",\n",
    "    \"credit\",\n",
    "    \"spam\",\n",
    "    \"parkinsons\",\n",
    "    \"wine_red\",\n",
    "    \"wine_white\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_mean_std(data, headers):\n",
    "    _mean = []\n",
    "    _std = []\n",
    "\n",
    "    for scenario in data:\n",
    "        local_mean = []\n",
    "        local_std = []\n",
    "        for vals in scenario:\n",
    "            if isinstance(vals, list):\n",
    "                local_mean.append(vals[0])\n",
    "                local_std.append(vals[1])\n",
    "            else:\n",
    "                local_mean.append(vals)\n",
    "                local_std.append(vals)\n",
    "        _mean.append(local_mean)\n",
    "        _std.append(local_std)\n",
    "    _mean_df = pd.DataFrame(_mean, columns=headers)\n",
    "    _std_df = pd.DataFrame(_std, columns=headers)\n",
    "\n",
    "    return _mean_df, _std_df\n",
    "\n",
    "\n",
    "for res in results:\n",
    "    if \"debug\" in res.name:\n",
    "        continue\n",
    "\n",
    "    if res.name not in df_names:\n",
    "        continue\n",
    "\n",
    "    with open(res) as f:\n",
    "        local_data = json.load(f)\n",
    "\n",
    "        headers = local_data[\"headers\"]\n",
    "\n",
    "        rmse_mean, rmse_std = generate_mean_std(local_data[\"rmse\"], headers)\n",
    "        distr_mean, distr_std = generate_mean_std(local_data[\"wasserstein\"], headers)\n",
    "\n",
    "    data[res.name] = {\n",
    "        rmse_key: (rmse_mean, rmse_std),\n",
    "        wass_key: (distr_mean, distr_std),\n",
    "    }\n",
    "\n",
    "\n",
    "results = {}\n",
    "models_cnt = len(headers) - 2\n",
    "df_names = sorted(data.keys())\n",
    "\n",
    "for dataset in df_names:\n",
    "    for metric in data[dataset]:\n",
    "        df, df_std = data[dataset][metric]\n",
    "\n",
    "        # Prediction norm\n",
    "        num_df = df._get_numeric_data()\n",
    "        num_df[num_df <= 0] = 1e-6\n",
    "\n",
    "        for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "            if scenario not in results:\n",
    "                results[scenario] = {}\n",
    "\n",
    "            for miss in [0.1, 0.3, 0.5, 0.7]:\n",
    "                if miss not in results[scenario]:\n",
    "                    results[scenario][miss] = {}\n",
    "\n",
    "                local_df = df[df[\"Scenario\"] == scenario].drop(columns=[\"Scenario\"])\n",
    "                local_df = local_df[local_df[\"miss_pct [0, 1]\"] == miss].drop(\n",
    "                    columns=[\"miss_pct [0, 1]\"]\n",
    "                )\n",
    "\n",
    "                local_df = local_df.rename(columns=remap_models)\n",
    "\n",
    "                if len(local_df) == 0:\n",
    "                    continue\n",
    "\n",
    "                local_df_std = df_std[df_std[\"Scenario\"] == scenario].drop(\n",
    "                    columns=[\"Scenario\"]\n",
    "                )\n",
    "                local_df_std = local_df_std[\n",
    "                    local_df_std[\"miss_pct [0, 1]\"] == miss\n",
    "                ].drop(columns=[\"miss_pct [0, 1]\"])\n",
    "\n",
    "                local_df_std = local_df_std.rename(columns=remap_models)\n",
    "\n",
    "                if metric not in results[scenario][miss]:\n",
    "                    results[scenario][miss][metric] = {}\n",
    "                for col in local_df.columns:\n",
    "                    if col not in results[scenario][miss][metric]:\n",
    "                        results[scenario][miss][metric][col] = {\n",
    "                            \"mean\": [],\n",
    "                            \"std\": [],\n",
    "                        }\n",
    "                    results[scenario][miss][metric][col][\"mean\"].append(\n",
    "                        min(local_df[col].values[0], 0.5)\n",
    "                    )\n",
    "                    results[scenario][miss][metric][col][\"std\"].append(\n",
    "                        min(local_df_std[col].values[0], 0.01)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(f\"diagrams_{experiment}\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fontsize = 14\n",
    "df_graph_len = models_cnt + 1\n",
    "\n",
    "\n",
    "def generate_plot_for_ax(ax, scenario, miss, metric):\n",
    "    offset = len(data)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=fontsize)\n",
    "\n",
    "    barWidth = 1\n",
    "\n",
    "    max_val = 0\n",
    "    idx = 0\n",
    "    for model in results[scenario][miss][metric]:\n",
    "        pos = [idx + df_graph_len * i * barWidth for i in range(offset)]\n",
    "\n",
    "        if len(pos) == 0:\n",
    "            continue\n",
    "\n",
    "        mod_mean = results[scenario][miss][metric][model][\"mean\"]\n",
    "        mod_std = results[scenario][miss][metric][model][\"std\"]\n",
    "        if max_val < max(mod_mean):\n",
    "            max_val = max(mod_mean)\n",
    "\n",
    "        ax.bar(\n",
    "            pos,\n",
    "            mod_mean,\n",
    "            yerr=mod_std,\n",
    "            width=barWidth,\n",
    "            label=str(model),\n",
    "            edgecolor=\"k\",\n",
    "        )\n",
    "        idx += barWidth\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1),\n",
    "        ncol=models_cnt,\n",
    "        prop={\"size\": fontsize},\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(\n",
    "        [df_graph_len * r + int(models_cnt / 2) for r in range(offset)],\n",
    "        df_names,\n",
    "        rotation=30,\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    ax.set_yticks(np.linspace(0, max_val + 0.1, num=5), fontsize=fontsize)\n",
    "    ax.set_ylabel(metric, fontsize=fontsize + 4)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_plot(scenario, miss):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "    offset = len(data)\n",
    "    metrics = list(results[scenario][miss].keys())\n",
    "    fig, axs = plt.subplots(len(metrics), figsize=(20, 8))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        generate_plot_for_ax(axs[idx], scenario, miss, metric)\n",
    "\n",
    "    plt.xlabel(f\"{scenario} simulation with {miss} missingness\", fontsize=fontsize)\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "    plt.savefig(output_dir / f\"general_overview_{scenario}_{miss}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for miss in [0.1, 0.3, 0.5]:\n",
    "        generate_plot(scenario, miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot by miss ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_axis = [0.1, 0.3, 0.5]\n",
    "\n",
    "fontsize = 14\n",
    "\n",
    "\n",
    "def generate_plot_for_ax(ax, scenario, metric, df_idx):\n",
    "    offset = len(data)\n",
    "\n",
    "    barWidth = 1\n",
    "\n",
    "    max_val = 0\n",
    "    idx = 0\n",
    "\n",
    "    for model in results[scenario][0.1][metric]:\n",
    "\n",
    "        datapoints = []\n",
    "        datapoints_std = []\n",
    "\n",
    "        for miss in results[scenario]:\n",
    "            if metric not in results[scenario][miss]:\n",
    "                continue\n",
    "\n",
    "            local_res = results[scenario][miss][metric][model][\"mean\"][df_idx]\n",
    "            local_res_std = results[scenario][miss][metric][model][\"std\"][df_idx]\n",
    "            datapoints.append(local_res)\n",
    "            datapoints_std.append(local_res_std)\n",
    "\n",
    "        ax.errorbar(\n",
    "            x_axis,\n",
    "            smooth_line(datapoints),\n",
    "            yerr=datapoints_std,\n",
    "            label=str(model),\n",
    "            linewidth=2,\n",
    "            marker=\"o\",\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(x_axis, fontsize=fontsize)\n",
    "    ax.set_ylabel(metric, fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_plot(scenario, df_idx, df_name):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "    offset = len(data)\n",
    "\n",
    "    metrics = list(results[scenario][0.1].keys())\n",
    "    fig, axs = plt.subplots(len(metrics), figsize=(10, 11))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        generate_plot_for_ax(axs[idx], scenario, metric, df_idx)\n",
    "\n",
    "    axs[0].legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0.15, 1.27),\n",
    "        ncol=int(models_cnt / 3),\n",
    "        prop={\"size\": fontsize},\n",
    "    )\n",
    "    fig.suptitle(f\"{scenario} simulation\", fontsize=fontsize)\n",
    "    plt.savefig(output_dir / f\"error_by_miss_{scenario}_{df_name}.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_df = [\"airfoil\", \"compression\", \"letter\", \"wine_white\", \"wine_red\"]\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for idx, df_name in enumerate(df_names):\n",
    "        if df_name not in plot_df:\n",
    "            continue\n",
    "        print(\"dataset \", df_name)\n",
    "        generate_plot(scenario, idx, df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
