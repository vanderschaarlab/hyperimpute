{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b69b924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 17:52:18.254027: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-24 17:52:18.254051: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bcebere/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "import hyperimpute.logger as log\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "enable_reproducible_results()\n",
    "\n",
    "imputers = Imputers()\n",
    "log.add(sink=sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa238824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "experiment = \"experiments_01_hyperimpute_with_hyperband\"\n",
    "\n",
    "\n",
    "def get_imputer():\n",
    "    return imputers.get(\"hyperimpute\", optimizer=\"hyperband\")\n",
    "\n",
    "\n",
    "def save_results(fname, results):\n",
    "    path = Path(experiment)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out = path / fname\n",
    "\n",
    "    with open(out, \"w\") as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "\n",
    "def evaluate_dataset_repeated(\n",
    "    name,\n",
    "    X_raw,\n",
    "    y,\n",
    "    ref_methods=[\n",
    "        \"mean\",\n",
    "        \"sklearn_ice\",\n",
    "        \"sklearn_missforest\",\n",
    "        \"softimpute\",\n",
    "        \"gain\",\n",
    "        \"sinkhorn\",\n",
    "    ],\n",
    "    scenarios=[\"MAR\", \"MCAR\", \"MNAR\"],\n",
    "    miss_pct=[0.1, 0.3, 0.5, 0.7],\n",
    "    n_iter=10,\n",
    "):\n",
    "    results = compare_models(\n",
    "        name=name,\n",
    "        evaluated_model=get_imputer(),\n",
    "        X_raw=X_raw,\n",
    "        ref_methods=ref_methods,\n",
    "        scenarios=scenarios,\n",
    "        miss_pct=miss_pct,\n",
    "        n_iter=n_iter,\n",
    "    )\n",
    "\n",
    "    save_results(name, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860d806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a13f18f0",
   "metadata": {},
   "source": [
    "## Sanity check in  debug mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9008e15c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-24T17:52:21.722676+0000][2072292][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2022-01-24T17:52:22.042112+0000][2072292][INFO]   > HyperImpute using inner optimization\n",
      "[2022-01-24T17:52:22.059925+0000][2072292][INFO]   > Imputation iter 0\n",
      "[2022-01-24T17:52:28.733552+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 8, 'lr': 0.001}) --- score : -0.0009761268991936495\n",
      "[2022-01-24T17:52:34.776875+0000][2072292][INFO]       >>> 0 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 7, 'lr': 0.0001}) --- score : -0.07424751948145078\n",
      "[2022-01-24T17:52:35.272200+0000][2072292][INFO]   > Imputation iter 1\n",
      "[2022-01-24T17:52:39.284613+0000][2072292][INFO]       >>> 0 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 7, 'lr': 0.0001}) --- score : -0.07424751948145078\n",
      "[2022-01-24T17:52:45.812427+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 8, 'lr': 0.01}) --- score : -0.0005880845858110835\n",
      "[2022-01-24T17:52:46.401805+0000][2072292][INFO]   > Imputation iter 2\n",
      "[2022-01-24T17:52:50.939200+0000][2072292][INFO]       >>> 0 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 7, 'lr': 0.0001}) --- score : -0.07424751948145078\n",
      "[2022-01-24T17:52:58.829158+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 8, 'lr': 0.0001}) --- score : -0.11051033846072256\n",
      "[2022-01-24T17:52:59.385092+0000][2072292][INFO]   > Imputation iter 3\n",
      "[2022-01-24T17:53:10.123925+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 8, 'lr': 0.01}) --- score : -0.09293443582023216\n",
      "[2022-01-24T17:53:18.399062+0000][2072292][INFO]       >>> 0 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 7, 'lr': 0.0001}) --- score : -0.07424751948145078\n",
      "[2022-01-24T17:53:19.067554+0000][2072292][INFO]   > Imputation iter 4\n",
      "[2022-01-24T17:53:25.832913+0000][2072292][INFO]       >>> 0 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 9, 'lr': 0.01}) --- score : -0.07077158702509032\n",
      "[2022-01-24T17:53:32.036839+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 8, 'lr': 0.01}) --- score : -0.0005880845858110835\n",
      "[2022-01-24T17:53:33.148962+0000][2072292][INFO]   > Imputation iter 5\n",
      "[2022-01-24T17:53:40.178640+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 8, 'lr': 0.01}) --- score : -0.0005880845858110835\n",
      "[2022-01-24T17:53:49.828372+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 8, 'lr': 0.01}) --- score : -0.09293443582023216\n",
      "[2022-01-24T17:53:50.260074+0000][2072292][INFO]   > Imputation iter 6\n",
      "[2022-01-24T17:53:55.926246+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 8, 'lr': 0.01}) --- score : -0.0005880845858110835\n",
      "[2022-01-24T17:54:01.739559+0000][2072292][INFO]       >>> 0 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 9, 'lr': 0.01}) --- score : -0.07077158702509032\n",
      "[2022-01-24T17:54:02.186759+0000][2072292][INFO]   > Imputation iter 7\n",
      "[2022-01-24T17:54:12.522273+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 8, 'lr': 0.01}) --- score : -0.09293443582023216\n",
      "[2022-01-24T17:54:17.716025+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 8, 'lr': 0.01}) --- score : -0.0005880845858110835\n",
      "[2022-01-24T17:54:18.174210+0000][2072292][INFO]   > Imputation iter 8\n",
      "[2022-01-24T17:54:25.823900+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.0001}) --- score : -0.08794521804161128\n",
      "[2022-01-24T17:54:31.387819+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 8, 'lr': 0.01}) --- score : -0.0005880845858110835\n",
      "[2022-01-24T17:54:31.916352+0000][2072292][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2022-01-24T17:54:31.921278+0000][2072292][INFO] benchmark hyperimpute took 130.02390599250793\n",
      "[2022-01-24T17:54:31.930232+0000][2072292][INFO] benchmark mean took 0.005402565002441406\n",
      "[2022-01-24T17:54:31.933574+0000][2072292][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2022-01-24T17:54:32.000126+0000][2072292][INFO]   > HyperImpute using inner optimization\n",
      "[2022-01-24T17:54:32.006355+0000][2072292][INFO]   > Imputation iter 0\n",
      "[2022-01-24T17:54:32.072355+0000][2072292][INFO]      >>> Column 0 <-- score -0.025332445310249772 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.150769+0000][2072292][INFO]      >>> Column 1 <-- score -0.01955711059677999 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.208489+0000][2072292][INFO]   > Imputation iter 1\n",
      "[2022-01-24T17:54:32.242487+0000][2072292][INFO]      >>> Column 0 <-- score -0.02385602673138841 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.321604+0000][2072292][INFO]      >>> Column 1 <-- score -0.018324394186719595 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.374108+0000][2072292][INFO]   > Imputation iter 2\n",
      "[2022-01-24T17:54:32.424043+0000][2072292][INFO]      >>> Column 0 <-- score -0.02385602673138841 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.495892+0000][2072292][INFO]      >>> Column 1 <-- score -0.018324394186719595 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.552140+0000][2072292][INFO]   > Imputation iter 3\n",
      "[2022-01-24T17:54:32.594172+0000][2072292][INFO]      >>> Column 0 <-- score -0.02385602673138841 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.659039+0000][2072292][INFO]      >>> Column 1 <-- score -0.018324394186719595 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.747135+0000][2072292][INFO]   > Imputation iter 4\n",
      "[2022-01-24T17:54:32.780297+0000][2072292][INFO]      >>> Column 0 <-- score -0.02385602673138841 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.832816+0000][2072292][INFO]      >>> Column 1 <-- score -0.01816110943046681 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.872659+0000][2072292][INFO]   > Imputation iter 5\n",
      "[2022-01-24T17:54:32.911998+0000][2072292][INFO]      >>> Column 0 <-- score -0.02385602673138841 <-- Model linear_regression\n",
      "[2022-01-24T17:54:32.964287+0000][2072292][INFO]      >>> Column 1 <-- score -0.01816110943046681 <-- Model linear_regression\n",
      "[2022-01-24T17:54:33.021160+0000][2072292][INFO]   > Imputation iter 6\n",
      "[2022-01-24T17:54:33.042978+0000][2072292][INFO]      >>> Column 0 <-- score -0.02385602673138841 <-- Model linear_regression\n",
      "[2022-01-24T17:54:33.104446+0000][2072292][INFO]      >>> Column 1 <-- score -0.01816110943046681 <-- Model linear_regression\n",
      "[2022-01-24T17:54:33.125515+0000][2072292][INFO]   > Imputation iter 7\n",
      "[2022-01-24T17:54:33.146407+0000][2072292][INFO]      >>> Column 0 <-- score -0.02385602673138841 <-- Model linear_regression\n",
      "[2022-01-24T17:54:33.177209+0000][2072292][INFO]      >>> Column 1 <-- score -0.01816110943046681 <-- Model linear_regression\n",
      "[2022-01-24T17:54:33.199611+0000][2072292][INFO]   > Imputation iter 8\n",
      "[2022-01-24T17:54:33.244493+0000][2072292][INFO]      >>> Column 0 <-- score -0.02385602673138841 <-- Model linear_regression\n",
      "[2022-01-24T17:54:33.299028+0000][2072292][INFO]      >>> Column 1 <-- score -0.01816110943046681 <-- Model linear_regression\n",
      "[2022-01-24T17:54:33.339357+0000][2072292][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2022-01-24T17:54:33.354949+0000][2072292][INFO] benchmark ice took 1.3963027000427246\n",
      "[2022-01-24T17:54:33.716728+0000][2072292][INFO]   > HyperImpute using inner optimization\n",
      "[2022-01-24T17:54:33.717502+0000][2072292][INFO]   > Imputation iter 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-24T17:54:41.164704+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 7, 'lr': 0.0001}) --- score : -0.030229456938029947\n",
      "[2022-01-24T17:54:49.007331+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.01}) --- score : -0.10245282187992719\n",
      "[2022-01-24T17:54:49.705884+0000][2072292][INFO]   > Imputation iter 1\n",
      "[2022-01-24T17:54:53.591231+0000][2072292][INFO]       >>> 2 -- best candidate catboost_regressor: ({'hyperparam_search_iterations': 27.0, 'depth': 5, 'n_estimators': 48, 'grow_policy': 3}) --- score : -0.024801864429013103\n",
      "[2022-01-24T17:54:59.670025+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.01}) --- score : -0.07584580865867473\n",
      "[2022-01-24T17:55:05.825267+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 7, 'lr': 0.0001}) --- score : -0.0032056049062145005\n",
      "[2022-01-24T17:55:06.127426+0000][2072292][INFO]   > Imputation iter 2\n",
      "[2022-01-24T17:55:13.732168+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.060557596680655676\n",
      "[2022-01-24T17:55:20.174128+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.002157704987866094\n",
      "[2022-01-24T17:55:20.512654+0000][2072292][INFO]   > Imputation iter 3\n",
      "[2022-01-24T17:55:25.749649+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.002157704987866094\n",
      "[2022-01-24T17:55:31.736425+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.060557596680655676\n",
      "[2022-01-24T17:55:32.073591+0000][2072292][INFO]   > Imputation iter 4\n",
      "[2022-01-24T17:55:36.750948+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.060557596680655676\n",
      "[2022-01-24T17:55:40.926797+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.002157704987866094\n",
      "[2022-01-24T17:55:41.228234+0000][2072292][INFO]   > Imputation iter 5\n",
      "[2022-01-24T17:55:44.407112+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 8, 'lr': 0.01}) --- score : -0.0013787630896750914\n",
      "[2022-01-24T17:55:46.529292+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.002157704987866094\n",
      "[2022-01-24T17:55:46.738304+0000][2072292][INFO]   > Imputation iter 6\n",
      "[2022-01-24T17:55:49.450611+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.060557596680655676\n",
      "[2022-01-24T17:55:51.999777+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.002157704987866094\n",
      "[2022-01-24T17:55:52.253996+0000][2072292][INFO]   > Imputation iter 7\n",
      "[2022-01-24T17:55:54.563230+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.001762117344020498\n",
      "[2022-01-24T17:55:57.900369+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 7, 'lr': 0.01}) --- score : -0.0009679079486151189\n",
      "[2022-01-24T17:55:58.134558+0000][2072292][INFO]   > Imputation iter 8\n",
      "[2022-01-24T17:56:01.080720+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.001762117344020498\n",
      "[2022-01-24T17:56:03.387119+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 7, 'lr': 0.01}) --- score : -0.0009679079486151189\n",
      "[2022-01-24T17:56:03.605667+0000][2072292][INFO]   > Imputation iter 9\n",
      "[2022-01-24T17:56:06.847064+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.060557596680655676\n",
      "[2022-01-24T17:56:09.795486+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.001762117344020498\n",
      "[2022-01-24T17:56:10.034293+0000][2072292][INFO]   > Imputation iter 10\n",
      "[2022-01-24T17:56:13.351879+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.060557596680655676\n",
      "[2022-01-24T17:56:16.305397+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 7, 'lr': 0.01}) --- score : -0.0009679079486151189\n",
      "[2022-01-24T17:56:16.540757+0000][2072292][INFO]   > Imputation iter 11\n",
      "[2022-01-24T17:56:20.334430+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.060557596680655676\n",
      "[2022-01-24T17:56:22.989325+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.001762117344020498\n",
      "[2022-01-24T17:56:23.212178+0000][2072292][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2022-01-24T17:56:23.215898+0000][2072292][INFO] benchmark hyperimpute took 109.53191471099854\n",
      "[2022-01-24T17:56:23.225083+0000][2072292][INFO] benchmark mean took 0.007033824920654297\n",
      "[2022-01-24T17:56:23.226449+0000][2072292][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2022-01-24T17:56:23.251030+0000][2072292][INFO]   > HyperImpute using inner optimization\n",
      "[2022-01-24T17:56:23.251631+0000][2072292][INFO]   > Imputation iter 0\n",
      "[2022-01-24T17:56:23.273811+0000][2072292][INFO]      >>> Column 1 <-- score -0.018088796690333205 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.305960+0000][2072292][INFO]      >>> Column 2 <-- score -0.07310797036232838 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.330823+0000][2072292][INFO]   > Imputation iter 1\n",
      "[2022-01-24T17:56:23.351439+0000][2072292][INFO]      >>> Column 1 <-- score -0.013490792922060346 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.383260+0000][2072292][INFO]      >>> Column 2 <-- score -0.06902257747492455 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.407243+0000][2072292][INFO]   > Imputation iter 2\n",
      "[2022-01-24T17:56:23.428066+0000][2072292][INFO]      >>> Column 1 <-- score -0.013490792922060346 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.461112+0000][2072292][INFO]      >>> Column 2 <-- score -0.06902257747492455 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.485742+0000][2072292][INFO]   > Imputation iter 3\n",
      "[2022-01-24T17:56:23.507023+0000][2072292][INFO]      >>> Column 1 <-- score -0.013490792922060346 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.538069+0000][2072292][INFO]      >>> Column 2 <-- score -0.06880930932822518 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.565751+0000][2072292][INFO]   > Imputation iter 4\n",
      "[2022-01-24T17:56:23.587686+0000][2072292][INFO]      >>> Column 1 <-- score -0.013183621234141334 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.620547+0000][2072292][INFO]      >>> Column 2 <-- score -0.06880930932822518 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.642961+0000][2072292][INFO]   > Imputation iter 5\n",
      "[2022-01-24T17:56:23.663142+0000][2072292][INFO]      >>> Column 1 <-- score -0.013183621234141334 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.695371+0000][2072292][INFO]      >>> Column 2 <-- score -0.06880930932822518 <-- Model linear_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-24T17:56:23.718420+0000][2072292][INFO]   > Imputation iter 6\n",
      "[2022-01-24T17:56:23.740485+0000][2072292][INFO]      >>> Column 1 <-- score -0.012938599111208256 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.774179+0000][2072292][INFO]      >>> Column 2 <-- score -0.06880930932822518 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.797004+0000][2072292][INFO]   > Imputation iter 7\n",
      "[2022-01-24T17:56:23.817869+0000][2072292][INFO]      >>> Column 1 <-- score -0.012938599111208256 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.852455+0000][2072292][INFO]      >>> Column 2 <-- score -0.06867707142418976 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.876435+0000][2072292][INFO]   > Imputation iter 8\n",
      "[2022-01-24T17:56:23.896315+0000][2072292][INFO]      >>> Column 1 <-- score -0.012938599111208256 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.929611+0000][2072292][INFO]      >>> Column 2 <-- score -0.06867707142418976 <-- Model linear_regression\n",
      "[2022-01-24T17:56:23.955027+0000][2072292][INFO]   > Imputation iter 9\n",
      "[2022-01-24T17:56:23.975979+0000][2072292][INFO]      >>> Column 1 <-- score -0.012938599111208256 <-- Model linear_regression\n",
      "[2022-01-24T17:56:24.029698+0000][2072292][INFO]      >>> Column 2 <-- score -0.06867707142418976 <-- Model linear_regression\n",
      "[2022-01-24T17:56:24.071473+0000][2072292][INFO]   > Imputation iter 10\n",
      "[2022-01-24T17:56:24.100534+0000][2072292][INFO]      >>> Column 1 <-- score -0.012938599111208256 <-- Model linear_regression\n",
      "[2022-01-24T17:56:24.150278+0000][2072292][INFO]      >>> Column 2 <-- score -0.06867707142418976 <-- Model linear_regression\n",
      "[2022-01-24T17:56:24.179238+0000][2072292][INFO]   > Imputation iter 11\n",
      "[2022-01-24T17:56:24.211638+0000][2072292][INFO]      >>> Column 1 <-- score -0.012938599111208256 <-- Model linear_regression\n",
      "[2022-01-24T17:56:24.250499+0000][2072292][INFO]      >>> Column 2 <-- score -0.06867707142418976 <-- Model linear_regression\n",
      "[2022-01-24T17:56:24.291162+0000][2072292][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2022-01-24T17:56:24.295878+0000][2072292][INFO] benchmark ice took 1.061955213546753\n",
      "[2022-01-24T17:56:24.417800+0000][2072292][INFO]   > HyperImpute using inner optimization\n",
      "[2022-01-24T17:56:24.418352+0000][2072292][INFO]   > Imputation iter 0\n",
      "[2022-01-24T17:56:27.849152+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.001}) --- score : -0.032378891479976676\n",
      "[2022-01-24T17:56:30.979712+0000][2072292][INFO]       >>> 1 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 8, 'lr': 0.0001}) --- score : -0.0025964467264208884\n",
      "[2022-01-24T17:56:31.243917+0000][2072292][INFO]   > Imputation iter 1\n",
      "[2022-01-24T17:56:33.726451+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 7, 'lr': 0.001}) --- score : -0.0025700721979922303\n",
      "[2022-01-24T17:56:36.903724+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 8, 'lr': 0.001}) --- score : -0.1033087285989717\n",
      "[2022-01-24T17:56:37.123445+0000][2072292][INFO]   > Imputation iter 2\n",
      "[2022-01-24T17:56:39.527439+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 7, 'lr': 0.001}) --- score : -0.0025700721979922303\n",
      "[2022-01-24T17:56:42.875176+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.01}) --- score : -0.09965976572629137\n",
      "[2022-01-24T17:56:43.206889+0000][2072292][INFO]   > Imputation iter 3\n",
      "[2022-01-24T17:56:46.299523+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 7, 'lr': 0.0001}) --- score : -0.0018123769669244588\n",
      "[2022-01-24T17:56:49.721061+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.01}) --- score : -0.09965976572629137\n",
      "[2022-01-24T17:56:49.948174+0000][2072292][INFO]   > Imputation iter 4\n",
      "[2022-01-24T17:56:52.931388+0000][2072292][INFO]       >>> 2 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27, 'max_depth': 8, 'lr': 0.001}) --- score : -0.0018021615275742179\n",
      "[2022-01-24T17:56:56.513103+0000][2072292][INFO]       >>> 3 -- best candidate xgboost_regressor: ({'hyperparam_search_iterations': 27.0, 'max_depth': 9, 'lr': 0.01}) --- score : -0.09965976572629137\n",
      "[2022-01-24T17:56:56.781687+0000][2072292][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2022-01-24T17:56:56.784867+0000][2072292][INFO] benchmark hyperimpute took 32.380064964294434\n",
      "[2022-01-24T17:56:56.793674+0000][2072292][INFO] benchmark mean took 0.005822420120239258\n",
      "[2022-01-24T17:56:56.795255+0000][2072292][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2022-01-24T17:56:56.815867+0000][2072292][INFO]   > HyperImpute using inner optimization\n",
      "[2022-01-24T17:56:56.816536+0000][2072292][INFO]   > Imputation iter 0\n",
      "[2022-01-24T17:56:56.850214+0000][2072292][INFO]      >>> Column 1 <-- score -0.019112247154389844 <-- Model linear_regression\n",
      "[2022-01-24T17:56:56.899471+0000][2072292][INFO]      >>> Column 2 <-- score -0.07285400193282954 <-- Model linear_regression\n",
      "[2022-01-24T17:56:56.934562+0000][2072292][INFO]   > Imputation iter 1\n",
      "[2022-01-24T17:56:56.965708+0000][2072292][INFO]      >>> Column 1 <-- score -0.014830072224270956 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.003366+0000][2072292][INFO]      >>> Column 2 <-- score -0.0716038796896942 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.037707+0000][2072292][INFO]   > Imputation iter 2\n",
      "[2022-01-24T17:56:57.065309+0000][2072292][INFO]      >>> Column 1 <-- score -0.01447863135216582 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.102095+0000][2072292][INFO]      >>> Column 2 <-- score -0.07054907604449107 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.129756+0000][2072292][INFO]   > Imputation iter 3\n",
      "[2022-01-24T17:56:57.162231+0000][2072292][INFO]      >>> Column 1 <-- score -0.014119660696923178 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.214148+0000][2072292][INFO]      >>> Column 2 <-- score -0.07054907604449107 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.253283+0000][2072292][INFO]   > Imputation iter 4\n",
      "[2022-01-24T17:56:57.290996+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.350549+0000][2072292][INFO]      >>> Column 2 <-- score -0.07007613336606905 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.384849+0000][2072292][INFO]   > Imputation iter 5\n",
      "[2022-01-24T17:56:57.416886+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.468728+0000][2072292][INFO]      >>> Column 2 <-- score -0.07007613336606905 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.508641+0000][2072292][INFO]   > Imputation iter 6\n",
      "[2022-01-24T17:56:57.551204+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.612186+0000][2072292][INFO]      >>> Column 2 <-- score -0.07007613336606905 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.653493+0000][2072292][INFO]   > Imputation iter 7\n",
      "[2022-01-24T17:56:57.685526+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.743931+0000][2072292][INFO]      >>> Column 2 <-- score -0.06956366824760948 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.782445+0000][2072292][INFO]   > Imputation iter 8\n",
      "[2022-01-24T17:56:57.816817+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.872217+0000][2072292][INFO]      >>> Column 2 <-- score -0.0688433697172655 <-- Model linear_regression\n",
      "[2022-01-24T17:56:57.908764+0000][2072292][INFO]   > Imputation iter 9\n",
      "[2022-01-24T17:56:57.937216+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-24T17:56:57.981406+0000][2072292][INFO]      >>> Column 2 <-- score -0.0688433697172655 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.022912+0000][2072292][INFO]   > Imputation iter 10\n",
      "[2022-01-24T17:56:58.052605+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.108994+0000][2072292][INFO]      >>> Column 2 <-- score -0.0688433697172655 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.155016+0000][2072292][INFO]   > Imputation iter 11\n",
      "[2022-01-24T17:56:58.187278+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.232032+0000][2072292][INFO]      >>> Column 2 <-- score -0.0688433697172655 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.267834+0000][2072292][INFO]   > Imputation iter 12\n",
      "[2022-01-24T17:56:58.298910+0000][2072292][INFO]      >>> Column 1 <-- score -0.014065498293187987 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.346906+0000][2072292][INFO]      >>> Column 2 <-- score -0.06869064531305262 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.375782+0000][2072292][INFO]   > Imputation iter 13\n",
      "[2022-01-24T17:56:58.399453+0000][2072292][INFO]      >>> Column 1 <-- score -0.014018317595396783 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.443125+0000][2072292][INFO]      >>> Column 2 <-- score -0.06869064531305262 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.474020+0000][2072292][INFO]   > Imputation iter 14\n",
      "[2022-01-24T17:56:58.499871+0000][2072292][INFO]      >>> Column 1 <-- score -0.014018317595396783 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.542453+0000][2072292][INFO]      >>> Column 2 <-- score -0.06869064531305262 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.577973+0000][2072292][INFO]   > Imputation iter 15\n",
      "[2022-01-24T17:56:58.604041+0000][2072292][INFO]      >>> Column 1 <-- score -0.014018317595396783 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.640352+0000][2072292][INFO]      >>> Column 2 <-- score -0.06869064531305262 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.670218+0000][2072292][INFO]   > Imputation iter 16\n",
      "[2022-01-24T17:56:58.699815+0000][2072292][INFO]      >>> Column 1 <-- score -0.014018317595396783 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.746239+0000][2072292][INFO]      >>> Column 2 <-- score -0.06869064531305262 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.781725+0000][2072292][INFO]   > Imputation iter 17\n",
      "[2022-01-24T17:56:58.812296+0000][2072292][INFO]      >>> Column 1 <-- score -0.014018317595396783 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.849866+0000][2072292][INFO]      >>> Column 2 <-- score -0.06869064531305262 <-- Model linear_regression\n",
      "[2022-01-24T17:56:58.880318+0000][2072292][INFO]      >>>> Early stopping on objective diff iteration\n",
      "[2022-01-24T17:56:58.884722+0000][2072292][INFO] benchmark ice took 2.083353042602539\n",
      "[2022-01-24T17:56:58.886641+0000][2072292][INFO] benchmark took 277.15169405937195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Scenario  </th><th style=\"text-align: right;\">  miss_pct [0, 1]</th><th>Our method       </th><th>mean           </th><th>ice             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>MAR       </td><td style=\"text-align: right;\">              0.3</td><td>0.1509 +/- 0.0307</td><td>0.3238 +/- 0.03</td><td>0.2867 +/- 0.021</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "\n",
      "Wasserstein score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Scenario  </th><th style=\"text-align: right;\">  miss_pct [0, 1]</th><th>Our method       </th><th>mean             </th><th>ice              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>MAR       </td><td style=\"text-align: right;\">              0.3</td><td>0.0249 +/- 0.0072</td><td>0.2482 +/- 0.0344</td><td>0.1389 +/- 0.0119</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "y = df[5]\n",
    "X_raw = df.drop(columns=[5])\n",
    "\n",
    "evaluate_dataset_repeated(\n",
    "    \"airfoil_debug\",\n",
    "    X_raw,\n",
    "    y,\n",
    "    scenarios=[\"MAR\"],\n",
    "    ref_methods=[\"mean\", \"ice\"],\n",
    "    n_iter=3,\n",
    "    miss_pct=[0.3],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47cf927",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b57094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperimpute.logger as log\n",
    "\n",
    "log.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d154c51",
   "metadata": {},
   "source": [
    "| Dataset     | Length | Features |\n",
    "|-------------|--------|----------|\n",
    "| airfoil     | 1503   | 6        |\n",
    "| blood       | 748    | 5        |\n",
    "| bc          | 569    | 30       |\n",
    "| california  | 20640  | 8        |\n",
    "| climate     | 540    | 21       |\n",
    "| compression | 1030   | 9        |\n",
    "| slump       | 103    | 11       |\n",
    "| sonar       | 208    | 61       |\n",
    "| diabetes    | 442    | 10       |\n",
    "| wine_red    | 1599   | 12       |\n",
    "| wine_white  | 4898   | 12       |\n",
    "| yeast       | 1484   | 10       |\n",
    "| iris        | 150    | 4        |\n",
    "| libras      | 360    | 91       |\n",
    "| parkinsons  | 195    | 24       |\n",
    "| yacht       | 308    | 7        |\n",
    "| ionosphere  | 351    | 35       |\n",
    "| letter      | 20000  | 17       |\n",
    "| spam        | 4600   | 58       |\n",
    "| credit      | 690    | 16       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e804b73",
   "metadata": {},
   "source": [
    "## Dataset: UCI Airfoil Self-Noise Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/airfoil+self-noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce05b6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"airfoil\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e948afbe",
   "metadata": {},
   "source": [
    "## Dataset: Breast Cancer Wisconsin (Diagnostic)\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ef088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X_raw, y = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"bc\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748baa7",
   "metadata": {},
   "source": [
    "## Concrete Compressive Strength Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/concrete+compressive+strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"compression\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee79c8",
   "metadata": {},
   "source": [
    "## Wine-Red dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality Data Set\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a654176",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "\n",
    "y = df[last_col]\n",
    "mapped_labels = sorted(y.unique())\n",
    "mapping = {}\n",
    "for idx, label in enumerate(mapped_labels):\n",
    "    mapping[label] = idx\n",
    "y = y.map(mapping)\n",
    "\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"wine_red\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47233931",
   "metadata": {},
   "source": [
    "## Wine-White dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "\n",
    "y = df[last_col]\n",
    "mapped_labels = sorted(y.unique())\n",
    "mapping = {}\n",
    "for idx, label in enumerate(mapped_labels):\n",
    "    mapping[label] = idx\n",
    "y = y.map(mapping)\n",
    "\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"wine_white\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32ed49",
   "metadata": {},
   "source": [
    "## Yeast Data Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\",\n",
    "    sep=\"\\s+\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "df = df.drop(columns=[0])\n",
    "\n",
    "for col in [9]:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b2f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "evaluate_dataset_repeated(\"yeast\", X_raw, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2927c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74bb2e4a",
   "metadata": {},
   "source": [
    "## Diabetes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1572f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"diabetes\", X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a31f9",
   "metadata": {},
   "source": [
    "## Iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"iris\", X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86166d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "884eb0e7",
   "metadata": {},
   "source": [
    "## Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac697da",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"ionosphere\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421f99b",
   "metadata": {},
   "source": [
    "## Libras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d01aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df53386",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"libras\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff518fc0",
   "metadata": {},
   "source": [
    "## Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",\n",
    "    sep=\",\",\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "df = df.drop(columns=[\"name\"])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"parkinsons\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc884b32",
   "metadata": {},
   "source": [
    "## Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"spam\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017cb3d",
   "metadata": {},
   "source": [
    "## Letter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"letter\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed24558",
   "metadata": {},
   "source": [
    "## Credit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55edc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "last_col = df.columns[-1]\n",
    "y = df[last_col]\n",
    "X_raw = df.drop(columns=[last_col])\n",
    "\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset_repeated(\"credit\", X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff67c9",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beda015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def smooth_line(src: list) -> list:\n",
    "    return signal.savgol_filter(src, 3, 1)\n",
    "\n",
    "\n",
    "X_raw_diab, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw_breast_cancer, _ = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_raw_california, _ = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_raw_iris, y_raw_iris = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "climate_model_samples = np.loadtxt(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat\",\n",
    "    skiprows=1,\n",
    ")\n",
    "climate_model_df = pd.DataFrame(climate_model_samples)\n",
    "\n",
    "raw_datasets = {\n",
    "    \"airfoil\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "        header=None,\n",
    "        sep=\"\\\\t\",\n",
    "    ),\n",
    "    \"blood\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\"\n",
    "    ),\n",
    "    \"bc\": X_raw_breast_cancer,\n",
    "    \"california\": X_raw_california,\n",
    "    \"climate\": climate_model_df,\n",
    "    \"compression\": pd.read_excel(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    "    ),\n",
    "    \"slump\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\"\n",
    "    ),\n",
    "    \"sonar\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"diabetes\": X_raw_diab,\n",
    "    \"wine_red\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"wine_white\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"iris\": X_raw_iris,\n",
    "    \"libras\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"parkinsons\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",\n",
    "        sep=\",\",\n",
    "    ),\n",
    "    \"yacht\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data\",\n",
    "        sep=\"\\s+\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"ionosphere\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"letter\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"spam\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "    ),\n",
    "    \"credit\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\",\n",
    "        header=None,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87537f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse results\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "experiment = \"experiments_01_hyperimpute_with_hyperband\"\n",
    "results = Path(experiment).glob(\"*\")\n",
    "\n",
    "remap_models = {\n",
    "    \"Our method\": \"hyperimpute\",\n",
    "    \"sklearn_missforest\": \"missforest\",\n",
    "    \"sklearn_ice\": \"ice\",\n",
    "}\n",
    "norm_cols = [\n",
    "    \"Our method\",\n",
    "    \"mean\",\n",
    "    \"sklearn_missforest\",\n",
    "    \"sklearn_ice\",\n",
    "    \"gain\",\n",
    "    \"sinkhorn\",\n",
    "    \"softimpute\",\n",
    "]\n",
    "\n",
    "rmse_key = \"Mean RMSE\"\n",
    "wass_key = \"Mean Wasserstein distance\"\n",
    "pred_key = \"Mean downstream prediction error\"\n",
    "\n",
    "data = {}\n",
    "\n",
    "df_names = [\n",
    "    \"airfoil\",\n",
    "    \"bc\",\n",
    "    \"compression\",\n",
    "    \"diabetes\",\n",
    "    \"ionosphere\",\n",
    "    \"iris\",\n",
    "    \"libras\",\n",
    "    \"letter\",\n",
    "    \"credit\",\n",
    "    \"spam\",\n",
    "    \"parkinsons\",\n",
    "    \"wine_red\",\n",
    "    \"wine_white\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate_mean_std(data, headers):\n",
    "    _mean = []\n",
    "    _std = []\n",
    "\n",
    "    for scenario in data:\n",
    "        local_mean = []\n",
    "        local_std = []\n",
    "        for vals in scenario:\n",
    "            if isinstance(vals, list):\n",
    "                local_mean.append(vals[0])\n",
    "                local_std.append(vals[1])\n",
    "            else:\n",
    "                local_mean.append(vals)\n",
    "                local_std.append(vals)\n",
    "        _mean.append(local_mean)\n",
    "        _std.append(local_std)\n",
    "    _mean_df = pd.DataFrame(_mean, columns=headers)\n",
    "    _std_df = pd.DataFrame(_std, columns=headers)\n",
    "\n",
    "    return _mean_df, _std_df\n",
    "\n",
    "\n",
    "for res in results:\n",
    "    if \"debug\" in res.name:\n",
    "        continue\n",
    "\n",
    "    if res.name not in df_names:\n",
    "        continue\n",
    "\n",
    "    with open(res) as f:\n",
    "        local_data = json.load(f)\n",
    "\n",
    "        headers = local_data[\"headers\"]\n",
    "\n",
    "        rmse_mean, rmse_std = generate_mean_std(local_data[\"rmse\"], headers)\n",
    "        distr_mean, distr_std = generate_mean_std(local_data[\"wasserstein\"], headers)\n",
    "\n",
    "    data[res.name] = {\n",
    "        rmse_key: (rmse_mean, rmse_std),\n",
    "        wass_key: (distr_mean, distr_std),\n",
    "    }\n",
    "\n",
    "\n",
    "results = {}\n",
    "models_cnt = len(headers) - 2\n",
    "df_names = sorted(data.keys())\n",
    "\n",
    "for dataset in df_names:\n",
    "    for metric in data[dataset]:\n",
    "        df, df_std = data[dataset][metric]\n",
    "\n",
    "        # Prediction norm\n",
    "        num_df = df._get_numeric_data()\n",
    "        num_df[num_df <= 0] = 1e-6\n",
    "\n",
    "        for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "            if scenario not in results:\n",
    "                results[scenario] = {}\n",
    "\n",
    "            for miss in [0.1, 0.3, 0.5, 0.7]:\n",
    "                if miss not in results[scenario]:\n",
    "                    results[scenario][miss] = {}\n",
    "\n",
    "                local_df = df[df[\"Scenario\"] == scenario].drop(columns=[\"Scenario\"])\n",
    "                local_df = local_df[local_df[\"miss_pct [0, 1]\"] == miss].drop(\n",
    "                    columns=[\"miss_pct [0, 1]\"]\n",
    "                )\n",
    "\n",
    "                local_df = local_df.rename(columns=remap_models)\n",
    "\n",
    "                if len(local_df) == 0:\n",
    "                    continue\n",
    "\n",
    "                local_df_std = df_std[df_std[\"Scenario\"] == scenario].drop(\n",
    "                    columns=[\"Scenario\"]\n",
    "                )\n",
    "                local_df_std = local_df_std[\n",
    "                    local_df_std[\"miss_pct [0, 1]\"] == miss\n",
    "                ].drop(columns=[\"miss_pct [0, 1]\"])\n",
    "\n",
    "                local_df_std = local_df_std.rename(columns=remap_models)\n",
    "\n",
    "                if metric not in results[scenario][miss]:\n",
    "                    results[scenario][miss][metric] = {}\n",
    "                for col in local_df.columns:\n",
    "                    if col not in results[scenario][miss][metric]:\n",
    "                        results[scenario][miss][metric][col] = {\n",
    "                            \"mean\": [],\n",
    "                            \"std\": [],\n",
    "                        }\n",
    "                    results[scenario][miss][metric][col][\"mean\"].append(\n",
    "                        min(local_df[col].values[0], 0.5)\n",
    "                    )\n",
    "                    results[scenario][miss][metric][col][\"std\"].append(\n",
    "                        min(local_df_std[col].values[0], 0.01)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539c770",
   "metadata": {},
   "source": [
    "## General overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(f\"diagrams_{experiment}\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b692c04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fontsize = 14\n",
    "df_graph_len = models_cnt + 1\n",
    "\n",
    "\n",
    "def generate_plot_for_ax(ax, scenario, miss, metric):\n",
    "    offset = len(data)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=fontsize)\n",
    "\n",
    "    barWidth = 1\n",
    "\n",
    "    max_val = 0\n",
    "    idx = 0\n",
    "    for model in results[scenario][miss][metric]:\n",
    "        pos = [idx + df_graph_len * i * barWidth for i in range(offset)]\n",
    "\n",
    "        if len(pos) == 0:\n",
    "            continue\n",
    "\n",
    "        mod_mean = results[scenario][miss][metric][model][\"mean\"]\n",
    "        mod_std = results[scenario][miss][metric][model][\"std\"]\n",
    "        if max_val < max(mod_mean):\n",
    "            max_val = max(mod_mean)\n",
    "\n",
    "        ax.bar(\n",
    "            pos,\n",
    "            mod_mean,\n",
    "            yerr=mod_std,\n",
    "            width=barWidth,\n",
    "            label=str(model),\n",
    "            edgecolor=\"k\",\n",
    "        )\n",
    "        idx += barWidth\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1),\n",
    "        ncol=models_cnt,\n",
    "        prop={\"size\": fontsize},\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(\n",
    "        [df_graph_len * r + int(models_cnt / 2) for r in range(offset)],\n",
    "        df_names,\n",
    "        rotation=30,\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    ax.set_yticks(np.linspace(0, max_val + 0.1, num=5), fontsize=fontsize)\n",
    "    ax.set_ylabel(metric, fontsize=fontsize + 4)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_plot(scenario, miss):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "    offset = len(data)\n",
    "    metrics = list(results[scenario][miss].keys())\n",
    "    fig, axs = plt.subplots(len(metrics), figsize=(20, 8))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        generate_plot_for_ax(axs[idx], scenario, miss, metric)\n",
    "\n",
    "    plt.xlabel(f\"{scenario} simulation with {miss} missingness\", fontsize=fontsize)\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "    plt.savefig(output_dir / f\"general_overview_{scenario}_{miss}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for miss in [0.1, 0.3, 0.5]:\n",
    "        generate_plot(scenario, miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06a0f3",
   "metadata": {},
   "source": [
    "## Plot by miss ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840c8f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_axis = [0.1, 0.3, 0.5]\n",
    "\n",
    "fontsize = 14\n",
    "\n",
    "\n",
    "def generate_plot_for_ax(ax, scenario, metric, df_idx):\n",
    "    offset = len(data)\n",
    "\n",
    "    barWidth = 1\n",
    "\n",
    "    max_val = 0\n",
    "    idx = 0\n",
    "\n",
    "    for model in results[scenario][0.1][metric]:\n",
    "\n",
    "        datapoints = []\n",
    "        datapoints_std = []\n",
    "\n",
    "        for miss in results[scenario]:\n",
    "            if metric not in results[scenario][miss]:\n",
    "                continue\n",
    "\n",
    "            local_res = results[scenario][miss][metric][model][\"mean\"][df_idx]\n",
    "            local_res_std = results[scenario][miss][metric][model][\"std\"][df_idx]\n",
    "            datapoints.append(local_res)\n",
    "            datapoints_std.append(local_res_std)\n",
    "\n",
    "        ax.errorbar(\n",
    "            x_axis,\n",
    "            smooth_line(datapoints),\n",
    "            yerr=datapoints_std,\n",
    "            label=str(model),\n",
    "            linewidth=2,\n",
    "            marker=\"o\",\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(x_axis, fontsize=fontsize)\n",
    "    ax.set_ylabel(metric, fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_plot(scenario, df_idx, df_name):\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "    offset = len(data)\n",
    "\n",
    "    metrics = list(results[scenario][0.1].keys())\n",
    "    fig, axs = plt.subplots(len(metrics), figsize=(10, 11))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        generate_plot_for_ax(axs[idx], scenario, metric, df_idx)\n",
    "\n",
    "    axs[0].legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0.15, 1.27),\n",
    "        ncol=int(models_cnt / 3),\n",
    "        prop={\"size\": fontsize},\n",
    "    )\n",
    "    fig.suptitle(f\"{scenario} simulation\", fontsize=fontsize)\n",
    "    plt.savefig(output_dir / f\"error_by_miss_{scenario}_{df_name}.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_df = [\"airfoil\", \"compression\", \"letter\", \"wine_white\", \"wine_red\"]\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    for idx, df_name in enumerate(df_names):\n",
    "        if df_name not in plot_df:\n",
    "            continue\n",
    "        print(\"dataset \", df_name)\n",
    "        generate_plot(scenario, idx, df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9146505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff9b339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
