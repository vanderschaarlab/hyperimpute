{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f97fd9c",
   "metadata": {},
   "source": [
    "## Benchmark models using the missingness simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d25e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "from hyperimpute.utils.benchmarks import compare_models\n",
    "\n",
    "imputer = Imputers().get(\n",
    "    \"hyperimpute\",  # the name of the imputation method.\n",
    "    # The rest of the kwargs are specific to the method\n",
    "    # optimizer: str. The optimizer to use: simple, hyperband, bayesian\n",
    "    optimizer=\"hyperband\",\n",
    "    # classifier_seed: list. Model search pool for categorical columns.\n",
    "    classifier_seed=[\"logistic_regression\", \"catboost\", \"xgboost\", \"random_forest\"],\n",
    "    # regression_seed: list. Model search pool for continuous columns.\n",
    "    regression_seed=[\n",
    "        \"linear_regression\",\n",
    "        \"catboost_regressor\",\n",
    "        \"xgboost_regressor\",\n",
    "        \"random_forest_regressor\",\n",
    "    ],\n",
    "    # class_threshold: int. how many max unique items must be in the column to be is associated with categorical\n",
    "    class_threshold=5,\n",
    "    # imputation_order: int. 0 - ascending, 1 - descending, 2 - random\n",
    "    imputation_order=2,\n",
    "    # n_inner_iter: int. number of imputation iterations\n",
    "    n_inner_iter=10,\n",
    "    # select_model_by_column: bool. If true, select a different model for each column. Else, it reuses the model chosen for the first column.\n",
    "    select_model_by_column=True,\n",
    "    # select_model_by_iteration: bool. If true, selects new models for each iteration. Else, it reuses the models chosen in the first iteration.\n",
    "    select_model_by_iteration=True,\n",
    "    # select_lazy: bool. If false, starts the optimizer on every column unless other restrictions apply. Else, if for the current iteration there is a trend(at least to columns of the same type got the same model from the optimizer), it reuses the same model class for all the columns without starting the optimizer.\n",
    "    select_lazy=True,\n",
    "    # select_patience: int. How many iterations without objective function improvement to wait.\n",
    "    select_patience=5,\n",
    ")\n",
    "\n",
    "# Load baseline dataset\n",
    "X, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "# Run benchmarks\n",
    "_ = compare_models(\n",
    "    name=\"example\",\n",
    "    evaluated_model=imputer,\n",
    "    X_raw=X,\n",
    "    ref_methods=[\"sklearn_ice\"],\n",
    "    scenarios=[\"MAR\"],\n",
    "    miss_pct=[0.3, 0.5],\n",
    "    n_iter=2,\n",
    "    n_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec28cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
