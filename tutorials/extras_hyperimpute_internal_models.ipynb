{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X_raw_diab, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw_breast_cancer, _ = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_raw_california, _ = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_raw_iris, y_raw_iris = load_iris(as_frame = True, return_X_y = True)\n",
    "\n",
    "climate_model_samples = np.loadtxt(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat\",\n",
    "    skiprows=1,\n",
    ")\n",
    "climate_model_df = pd.DataFrame(climate_model_samples)\n",
    "\n",
    "raw_datasets = {\n",
    "    \"airfoil\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "        header=None,\n",
    "        sep=\"\\\\t\",\n",
    "    ),\n",
    "    \"blood\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\"\n",
    "    ),\n",
    "    \"bc\": X_raw_breast_cancer,\n",
    "    \"california\": X_raw_california,\n",
    "    \"climate\": climate_model_df,\n",
    "    \"compression\": pd.read_excel(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    "    ),\n",
    "    \"slump\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\"\n",
    "    ),\n",
    "    \"sonar\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"diabetes\": X_raw_diab,\n",
    "    \"wine_red\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"wine_white\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"yeast\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\",\n",
    "        sep=\"\\s+\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"iris\": X_raw_iris,\n",
    "    \"libras\":pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",sep=\",\", header = None),\n",
    "    \"parkinsons\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",sep=\",\"),\n",
    "    \"yacht\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data\",sep=\"\\s+\", header = None),\n",
    "    \"ionosphere\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",sep=\",\", header = None),\n",
    "    \"letter\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\", header = None),\n",
    "    \"spam\":pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"),\n",
    "    \"credit\":pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\", header = None),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1b564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79bf46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_imputation import simulate_scenarios\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imputer():\n",
    "    return imputers.get(\"hyperimpute\", \n",
    "        optimizer = \"simple\"\n",
    "    )\n",
    "\n",
    "def evaluate_dataset(name: str, X_raw: pd.DataFrame, \n",
    "    scenarios: list = [\"MAR\", \"MCAR\"],\n",
    "    miss_pct: list = [0.1, 0.3, 0.5, 0.7],\n",
    "    debug: bool = True,\n",
    "):\n",
    "    imputation_scenarios = simulate_scenarios(X_raw, column_limit = 10)\n",
    "\n",
    "    out = {}\n",
    "    for scenario in scenarios:\n",
    "        out[scenario] = {}\n",
    "        for missingness in miss_pct:\n",
    "        \n",
    "            try:\n",
    "                x, x_miss, mask = imputation_scenarios[scenario][missingness]\n",
    "\n",
    "                model = get_imputer()\n",
    "                \n",
    "                model.fit_transform(x_miss)\n",
    "                \n",
    "                mod_names = []\n",
    "                for mod_idx in model.models():\n",
    "                    mod =  model.models()[mod_idx]\n",
    "                    mod_names.append(mod.name())\n",
    "                out[scenario][missingness] = mod_names\n",
    "                print(\"       > eval \", scenario, missingness, mod_names)\n",
    "                \n",
    "            except BaseException as e:\n",
    "                print(\"scenario failed\", str(e))\n",
    "                continue\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = {}\n",
    "for dataset in raw_datasets:\n",
    "    print(\"  > eval \", dataset)\n",
    "\n",
    "    df = raw_datasets[dataset]\n",
    "    \n",
    "    selected_models[dataset] = evaluate_dataset(dataset, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd126cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"general_results/selected_models.json\", \"w\") as f:\n",
    "    json.dump(selected_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde8fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
