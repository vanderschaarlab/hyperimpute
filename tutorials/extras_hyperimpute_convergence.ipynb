{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e810e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "X_raw_diab, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw_breast_cancer, _ = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_raw_california, _ = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_raw_iris, y_raw_iris = load_iris(as_frame = True, return_X_y = True)\n",
    "\n",
    "climate_model_samples = np.loadtxt(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat\",\n",
    "    skiprows=1,\n",
    ")\n",
    "climate_model_df = pd.DataFrame(climate_model_samples)\n",
    "\n",
    "raw_datasets = {\n",
    "    #\"airfoil\": pd.read_csv(\n",
    "    #    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    #    header=None,\n",
    "    #    sep=\"\\\\t\",\n",
    "    #),\n",
    "    #\"blood\": pd.read_csv(\n",
    "    #    \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\"\n",
    "    #),\n",
    "    #\"bc\": X_raw_breast_cancer,\n",
    "    #\"california\": X_raw_california,\n",
    "    #\"compression\": pd.read_excel(\n",
    "    #    \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    "    #),\n",
    "    #\"slump\": pd.read_csv(\n",
    "    #    \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\"\n",
    "    #),\n",
    "    #\"sonar\": pd.read_csv(\n",
    "    #    \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\",\n",
    "    #    header=None,\n",
    "    #),\n",
    "    #\"diabetes\": X_raw_diab,\n",
    "    \"parkinsons\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",sep=\",\"),\n",
    "    \"wine_red\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    #\"wine_white\": pd.read_csv(\n",
    "    #    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "    #    sep=\";\",\n",
    "    #),\n",
    "    #\"ionosphere\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",sep=\",\", header = None),\n",
    "    \"spam\":pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"),\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff1b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "\n",
    "enable_reproducible_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79bf46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 10:53:33.877865: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-21 10:53:33.877888: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bcebere/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from benchmark_imputation import simulate_scenarios\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "import hyperimpute.logger as log\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6609076",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Convergence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5900ca8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from benchmark_imputation import ws_score\n",
    "\n",
    "def get_imputer(cbk):\n",
    "    return imputers.get(\"hyperimpute\", \n",
    "        optimizer = \"hyperband\",\n",
    "        inner_loop_hook = cbk,\n",
    "        select_lazy = False,\n",
    "    )\n",
    "\n",
    "def evaluate_convergence(name: str, X_raw: pd.DataFrame, \n",
    "    scenarios: list = [\"MAR\"],\n",
    "    miss_pct: list = [0.3],\n",
    "    debug: bool = True,\n",
    "):\n",
    "    imputation_scenarios = simulate_scenarios(X_raw, column_limit = 10)\n",
    "\n",
    "    out = {}\n",
    "    traces = {}\n",
    "    for scenario in scenarios:\n",
    "        out[scenario] = {}\n",
    "        traces[scenario] = {}\n",
    "        \n",
    "        for missingness in miss_pct:\n",
    "        \n",
    "            try:\n",
    "                x, x_miss, mask = imputation_scenarios[scenario][missingness]\n",
    "\n",
    "                wass_scores = []\n",
    "                rmse_scores = []\n",
    "                def hook(outer_it, Xt):\n",
    "                    nonlocal rmse_scores\n",
    "                    nonlocal wass_scores\n",
    "                    distribution_score = ws_score(Xt, x)\n",
    "                    rmse_score = RMSE(np.asarray(Xt), np.asarray(x), np.asarray(mask))\n",
    "                    \n",
    "                    wass_scores.append(distribution_score)\n",
    "                    rmse_scores.append(rmse_score)\n",
    "                    #print(outer_it, distribution_score, rmse_score)\n",
    "        \n",
    "                model = get_imputer(hook)\n",
    "                print(\"    eval model\", model.name())\n",
    "                model.fit_transform(x_miss.copy())\n",
    "                \n",
    "                full_trace = model.trace()\n",
    "                model_trace = full_trace[\"models\"]\n",
    "                trace = full_trace[\"objective\"]\n",
    "                \n",
    "                max_wait = len(wass_scores)\n",
    "                \n",
    "                for mod_idx in trace:\n",
    "                    if len(trace[mod_idx]) < max_wait:\n",
    "                        trace[mod_idx] += [trace[mod_idx][-1]] * (max_wait - len(trace[mod_idx]))\n",
    "                        \n",
    "                for mod_idx in trace:\n",
    "                    arr = np.asarray(trace[mod_idx])\n",
    "                    if arr[0] > 0:\n",
    "                        arr = 1 - arr\n",
    "                    else:\n",
    "                        arr = -arr\n",
    "                    trace[mod_idx] = arr\n",
    "                    \n",
    "                    \n",
    "                scores = []\n",
    "                for mod_idx in trace:\n",
    "                    score_len =  len(trace[mod_idx])\n",
    "                    break\n",
    "                    \n",
    "                for epoch in range(score_len):\n",
    "                    epoch_score = 0\n",
    "                    for mod_idx in trace:\n",
    "                        epoch_score +=  trace[mod_idx][epoch]\n",
    "                    scores.append(epoch_score)\n",
    "            except BaseException as e:\n",
    "                raise e\n",
    "                print(\"scenario failed\", str(e))\n",
    "                continue\n",
    "    return scores, wass_scores, rmse_scores, model_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c40f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"diagrams/convergence\")\n",
    "\n",
    "\n",
    "def perf_plot_dataset(dataset, scenario, miss):\n",
    "    \n",
    "    df = raw_datasets[dataset]\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "    optimizer_scores, wass_scores, rmse_scores, model_trace = evaluate_convergence(dataset, df, scenarios = [scenario], miss_pct = [miss])\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize = (15, 4))\n",
    "\n",
    "    axs[0].plot([ i for i in range(len(optimizer_scores))], optimizer_scores, label = \"Cumulative objective error\", color = \"orange\")\n",
    "    axs[0].legend()\n",
    "    axs[1].plot([ i for i in range(len(optimizer_scores))], wass_scores, label = \"Wasserstein distance\")\n",
    "    axs[1].legend()\n",
    "    axs[2].plot([ i for i in range(len(optimizer_scores))], rmse_scores, label = \"RMSE\", color = \"green\")\n",
    "    axs[2].legend()\n",
    "\n",
    "    axs[0].set_ylabel(f\"{scenario}: {dataset}: {miss}\")\n",
    "    axs[1].set_xlabel(f\"Iterations\")\n",
    "\n",
    "    plt.savefig(output_dir / f\"convergence_{scenario}_{dataset}_{miss}.png\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return optimizer_scores, wass_scores, rmse_scores, model_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3907d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval dataset parkinsons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 10:53:38.244177: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-21 10:53:38.244204: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-21 10:53:38.302477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-21 10:53:38.302500: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:tensorflow:From /home/bcebere/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/bcebere/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "dispatcher = Parallel(n_jobs=3)\n",
    "\n",
    "results = {}\n",
    "\n",
    "full_output = {}\n",
    "for dataset in raw_datasets:\n",
    "    results[dataset] = {}\n",
    "    scenario = \"MAR\"\n",
    "    miss = 0.3\n",
    "    \n",
    "    print(\"eval dataset\", dataset)\n",
    "    results[dataset][scenario] = {}\n",
    "    try:\n",
    "        full_opt_scores = []\n",
    "        full_was_scores = []\n",
    "        full_rmse_scores = []\n",
    "        full_trace = []\n",
    "        \n",
    "        bench_res = dispatcher(\n",
    "            delayed(perf_plot_dataset)(dataset, scenario, miss) for i in range(10))\n",
    "            \n",
    "            \n",
    "        for optimizer_scores, wass_scores, rmse_scores, traces in bench_res:\n",
    "            full_opt_scores.append(optimizer_scores)\n",
    "            full_was_scores.append(wass_scores)\n",
    "            full_rmse_scores.append(rmse_scores)\n",
    "            full_trace.append(traces)\n",
    "\n",
    "        full_output[dataset] = {\n",
    "            \"objective\": full_opt_scores,\n",
    "            \"mwd\": full_was_scores,\n",
    "            \"rmse\": full_rmse_scores,\n",
    "            \"model_trace\": full_trace,\n",
    "        }\n",
    "        results[dataset][scenario][miss] = (optimizer_scores, wass_scores, rmse_scores)\n",
    "    except BaseException as e:\n",
    "        print(\"scenario failed\", dataset, scenario, e)\n",
    "        raise e\n",
    "\n",
    "with open(\"general_results/convergence_traces.csv\", \"w\") as f:  \n",
    "    json.dump(full_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48cf0fd",
   "metadata": {},
   "source": [
    "## Convergence trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f193049",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df0226",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
