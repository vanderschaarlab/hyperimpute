{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ed2303",
   "metadata": {},
   "source": [
    "# Bayesian Optimization over standard imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "\n",
    "enable_reproducible_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a86c6",
   "metadata": {},
   "source": [
    "# Load imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers, ImputerPlugin\n",
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "from hyperimpute.utils.optimizer import EarlyStoppingExceeded, create_study\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "imputers.list()\n",
    "\n",
    "imputers_seed = [\n",
    "    \"miracle\",\n",
    "    \"miwae\",\n",
    "    \"gain\",\n",
    "    \"softimpute\",\n",
    "    \"sinkhorn\",\n",
    "    \"mean\",\n",
    "    \"sklearn_ice\",\n",
    "    \"most_frequent\",\n",
    "    \"median\",\n",
    "    \"EM\",\n",
    "    \"sklearn_missforest\",\n",
    "]\n",
    "\n",
    "subsample = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86c52a",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def ampute(x, mechanism, p_miss):\n",
    "    x_simulated = simulate_nan(x, p_miss, mechanism)\n",
    "\n",
    "    mask = x_simulated[\"mask\"]\n",
    "    x_miss = x_simulated[\"X_incomp\"]\n",
    "\n",
    "    return x, x_miss, mask\n",
    "\n",
    "\n",
    "def scale_data(X):\n",
    "    X = np.asarray(X)\n",
    "    preproc = MinMaxScaler()\n",
    "\n",
    "    return np.asarray(preproc.fit_transform(X))\n",
    "\n",
    "\n",
    "def simulate_scenarios(X):\n",
    "    X = scale_data(X)\n",
    "\n",
    "    datasets = {}\n",
    "\n",
    "    mechanisms = [\"MAR\", \"MNAR\", \"MCAR\"]\n",
    "    percentages = [0.2, 0.3]\n",
    "\n",
    "    for ampute_mechanism in mechanisms:\n",
    "        for p_miss in percentages:\n",
    "            if ampute_mechanism not in datasets:\n",
    "                datasets[ampute_mechanism] = {}\n",
    "\n",
    "            datasets[ampute_mechanism][p_miss] = ampute(X, ampute_mechanism, p_miss)\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1f90ba",
   "metadata": {},
   "source": [
    "# BO core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c853f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "\n",
    "def evaluate_plugin(\n",
    "    name: str,\n",
    "    plugin: ImputerPlugin,\n",
    "    X: np.ndarray,\n",
    "    X_miss: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    prev_best_score: float,\n",
    "):\n",
    "\n",
    "    study, pruner = create_study(\n",
    "        study_name=f\"{name}_imputer_evaluation_{plugin.name()}\",\n",
    "        direction=\"minimize\",\n",
    "        load_if_exists=False,\n",
    "        patience=5,\n",
    "    )\n",
    "\n",
    "    def evaluate_args(**kwargs: Any) -> float:\n",
    "        imputer = plugin(**kwargs)\n",
    "\n",
    "        imputed = imputer.fit_transform(X_miss.copy())\n",
    "        return RMSE(np.asarray(imputed), X, mask)\n",
    "\n",
    "    baseline_score = evaluate_args(**{})\n",
    "\n",
    "    if baseline_score < prev_best_score:\n",
    "        return baseline_score, {}\n",
    "\n",
    "    pruner.report_score(baseline_score)\n",
    "    if prev_best_score < 100:\n",
    "        pruner.report_score(prev_best_score)\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        args = plugin.sample_hyperparameters(trial)\n",
    "        pruner.check_trial(trial)\n",
    "\n",
    "        score = evaluate_args(**args)\n",
    "\n",
    "        pruner.report_score(score)\n",
    "\n",
    "        return score\n",
    "\n",
    "    try:\n",
    "        study.optimize(objective, n_trials=50, timeout=60 * 3)\n",
    "    except EarlyStoppingExceeded:\n",
    "        pass\n",
    "        # print(f\"Early stopping triggered for imputer {plugin.name()}\")\n",
    "\n",
    "    try:\n",
    "        if baseline_score > study.best_value:\n",
    "            return baseline_score, {}\n",
    "\n",
    "        return study.best_value, study.best_trial.params\n",
    "    except BaseException:\n",
    "        return baseline_score, {}\n",
    "\n",
    "\n",
    "def benchmark(\n",
    "    name: str,\n",
    "    X: np.ndarray,\n",
    "    X_miss: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "):\n",
    "    scores = {}\n",
    "    start = time.time()\n",
    "\n",
    "    best_score = 999\n",
    "    for plugin in imputers_seed:\n",
    "\n",
    "        plugin_t = imputers.get_type(plugin)\n",
    "        try:\n",
    "            score, params = evaluate_plugin(name, plugin_t, X, X_miss, mask, best_score)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "        except BaseException as e:\n",
    "            print(\"      >>>  Plugin failed\", plugin, e)\n",
    "            raise e\n",
    "\n",
    "        scores[plugin] = (score, params)\n",
    "\n",
    "    print(f\" iteration for {name} took {time.time() - start} seconds\")\n",
    "    print(\" iteration scores\", scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a09fa8",
   "metadata": {},
   "source": [
    "# Dataset: UCI Airfoil Self-Noise Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/airfoil+self-noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cc12e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "    header=None,\n",
    "    sep=\"\\\\t\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = subsample / len(df)\n",
    "X = df.sample(frac=frac).values\n",
    "\n",
    "imputation_scenarios = simulate_scenarios(X)\n",
    "\n",
    "\n",
    "results = []\n",
    "candidates = {}\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    print(\"Evaluating \", scenario)\n",
    "    x, x_miss, mask = imputation_scenarios[scenario][0.3]\n",
    "\n",
    "    bo_results = benchmark(\"airfoil\", x, x_miss, mask)\n",
    "\n",
    "    best_candidate = \"\"\n",
    "    best_score = 99999\n",
    "    best_params = {}\n",
    "    for plugin in bo_results:\n",
    "        score, params = bo_results[plugin]\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_candidate = plugin\n",
    "            best_params = params\n",
    "\n",
    "    results.append([scenario, best_candidate, best_score])\n",
    "    candidates[scenario] = (best_candidate, best_params)\n",
    "results\n",
    "\n",
    "headers = [\"Scenario\", \"BO selected estimator\", \"BO score\"]\n",
    "\n",
    "display(HTML(tabulate.tabulate(results, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset evaluation\n",
    "X = df.values\n",
    "imputation_scenarios = simulate_scenarios(X)\n",
    "\n",
    "results = []\n",
    "for scenario in candidates:\n",
    "    x, x_miss, mask = imputation_scenarios[scenario][0.3]\n",
    "\n",
    "    plugin, plugin_params = candidates[scenario]\n",
    "\n",
    "    model = imputers.get(plugin, **plugin_params)\n",
    "\n",
    "    imputed = model.fit_transform(x_miss.copy())\n",
    "\n",
    "    loss = RMSE(np.asarray(imputed), x, mask)\n",
    "\n",
    "    results.append([scenario, plugin, loss])\n",
    "\n",
    "headers = [\"Scenario\", \"BO-selected model\", \"RMSE on full dataset\"]\n",
    "\n",
    "\n",
    "display(HTML(tabulate.tabulate(results, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw methods evaluation\n",
    "ref_models = [\n",
    "    \"mean\",\n",
    "    \"sklearn_missforest\",\n",
    "    \"gain\",\n",
    "    \"EM\",\n",
    "    \"sklearn_ice\",\n",
    "    \"softimpute\",\n",
    "    \"sinkhorn\",\n",
    "    \"miracle\",\n",
    "    \"miwae\",\n",
    "]\n",
    "results = []\n",
    "for scenario in candidates:\n",
    "    x, x_miss, mask = imputation_scenarios[scenario][0.3]\n",
    "\n",
    "    local_res = [\n",
    "        scenario,\n",
    "    ]\n",
    "    for plugin in ref_models:\n",
    "\n",
    "        model = imputers.get(plugin)\n",
    "\n",
    "        imputed = model.fit_transform(x_miss.copy())\n",
    "\n",
    "        loss = RMSE(np.asarray(imputed), x, mask)\n",
    "\n",
    "        local_res.append(loss)\n",
    "\n",
    "    results.append(local_res)\n",
    "\n",
    "headers = [\"Scenario\"] + ref_models\n",
    "\n",
    "\n",
    "display(HTML(tabulate.tabulate(results, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ffd79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeafd502",
   "metadata": {},
   "source": [
    "# Dataset: Blood Transfusion Service Center Data Set\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b44219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\",\n",
    "    sep=\",\",\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = min(subsample / len(df), 1)\n",
    "X = df.sample(frac=frac).values\n",
    "\n",
    "imputation_scenarios = simulate_scenarios(X)\n",
    "\n",
    "\n",
    "results = []\n",
    "candidates = {}\n",
    "for scenario in [\"MAR\", \"MCAR\", \"MNAR\"]:\n",
    "    print(\"Evaluating \", scenario)\n",
    "    x, x_miss, mask = imputation_scenarios[scenario][0.3]\n",
    "\n",
    "    bo_results = benchmark(\"blood\", x, x_miss, mask)\n",
    "\n",
    "    best_candidate = \"\"\n",
    "    best_score = 99999\n",
    "    best_params = {}\n",
    "    for plugin in bo_results:\n",
    "        score, params = bo_results[plugin]\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_candidate = plugin\n",
    "            best_params = params\n",
    "\n",
    "    results.append([scenario, best_candidate, best_score])\n",
    "    candidates[scenario] = (best_candidate, best_params)\n",
    "results\n",
    "\n",
    "headers = [\"Scenario\", \"BO selected estimator\", \"BO score\"]\n",
    "\n",
    "display(HTML(tabulate.tabulate(results, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542dcbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset evaluation\n",
    "X = df.values\n",
    "imputation_scenarios = simulate_scenarios(X)\n",
    "\n",
    "results = []\n",
    "for scenario in candidates:\n",
    "    x, x_miss, mask = imputation_scenarios[scenario][0.3]\n",
    "\n",
    "    plugin, plugin_params = candidates[scenario]\n",
    "\n",
    "    model = imputers.get(plugin, **plugin_params)\n",
    "\n",
    "    imputed = model.fit_transform(x_miss.copy())\n",
    "\n",
    "    loss = RMSE(np.asarray(imputed), x, mask)\n",
    "\n",
    "    results.append([scenario, plugin, loss])\n",
    "\n",
    "headers = [\"Scenario\", \"BO-selected model\", \"RMSE on full dataset\"]\n",
    "\n",
    "\n",
    "display(HTML(tabulate.tabulate(results, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787836ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other methods evaluation\n",
    "\n",
    "ref_models = [\n",
    "    \"mean\",\n",
    "    \"sklearn_missforest\",\n",
    "    \"gain\",\n",
    "    \"EM\",\n",
    "    \"sklearn_ice\",\n",
    "    \"softimpute\",\n",
    "    \"sinkhorn\",\n",
    "    \"miracle\",\n",
    "    \"miwae\",\n",
    "]\n",
    "results = []\n",
    "for scenario in candidates:\n",
    "    x, x_miss, mask = imputation_scenarios[scenario][0.3]\n",
    "\n",
    "    local_res = [\n",
    "        scenario,\n",
    "    ]\n",
    "    for plugin in ref_models:\n",
    "\n",
    "        model = imputers.get(plugin)\n",
    "\n",
    "        imputed = model.fit_transform(x_miss.copy())\n",
    "\n",
    "        loss = RMSE(np.asarray(imputed), x, mask)\n",
    "\n",
    "        local_res.append(loss)\n",
    "\n",
    "    results.append(local_res)\n",
    "\n",
    "headers = [\"Scenario\"] + ref_models\n",
    "\n",
    "\n",
    "display(HTML(tabulate.tabulate(results, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb0e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff1544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e65be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
