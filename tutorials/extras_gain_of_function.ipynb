{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1242dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcebere/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#!pip install xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_iris\n",
    "import hyperimpute.logger as log\n",
    "\n",
    "X_raw_diab, _ = load_diabetes(as_frame=True, return_X_y=True)\n",
    "\n",
    "X_raw_breast_cancer, _ = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_raw_california, _ = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_raw_iris, y_raw_iris = load_iris(as_frame = True, return_X_y = True)\n",
    "\n",
    "climate_model_samples = np.loadtxt(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00252/pop_failures.dat\",\n",
    "    skiprows=1,\n",
    ")\n",
    "climate_model_df = pd.DataFrame(climate_model_samples)\n",
    "\n",
    "raw_datasets = {\n",
    "    \"airfoil\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\",\n",
    "        header=None,\n",
    "        sep=\"\\\\t\",\n",
    "    ),\n",
    "    \"wine_white\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "    \"spam\":pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"),\n",
    "    \"california\": X_raw_california, \n",
    "    \"sonar\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\",\n",
    "        header=None),\n",
    "    \"libras\":pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.data\",sep=\",\", header = None),\n",
    "    \"parkinsons\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",sep=\",\"),  \n",
    "    \"blood\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data\"\n",
    "    ), # prefers LRs\n",
    "    \"bc\": X_raw_breast_cancer, # prefers LR\n",
    "    \n",
    "    \"compression\": pd.read_excel(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    "    ),\n",
    "    \"slump\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\"\n",
    "    ),\n",
    "    \"diabetes\": X_raw_diab,\n",
    "    \"wine_red\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "        sep=\";\",\n",
    "    ),\n",
    "   \"yeast\": pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\",\n",
    "        sep=\"\\s+\",\n",
    "        header=None,\n",
    "    ),\n",
    "    \"iris\": X_raw_iris,\n",
    "    \"parkinsons\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data\",sep=\",\"),\n",
    "    \"ionosphere\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",sep=\",\", header = None),\n",
    "    \"credit\":pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\", header = None),\n",
    "    \"letter\": pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\", header = None),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd14cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96da0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 17:05:33.421175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-20 17:05:33.421198: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bcebere/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from benchmark_imputation import simulate_scenarios\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import hyperimpute.logger as log\n",
    "from hyperimpute.utils.metrics import print_score, generate_score\n",
    "from hyperimpute.utils.distributions import enable_reproducible_results\n",
    "\n",
    "enable_reproducible_results()\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c98750",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-20T17:05:34.744310+0200][412545][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: True\n",
      "[2022-01-20T17:05:34.750479+0200][412545][INFO] Iteration imputation: select_model_by_column: False, select_model_by_iteration: True\n",
      "[2022-01-20T17:05:34.756523+0200][412545][INFO] Iteration imputation: select_model_by_column: True, select_model_by_iteration: False\n",
      "[2022-01-20T17:05:34.761502+0200][412545][INFO] Iteration imputation: select_model_by_column: False, select_model_by_iteration: False\n",
      "[2022-01-20T17:05:34.766756+0200][412545][INFO] Iteration imputation: select_model_by_column: False, select_model_by_iteration: False\n",
      "[2022-01-20T17:05:34.772050+0200][412545][INFO] Iteration imputation: select_model_by_column: False, select_model_by_iteration: False\n",
      "[2022-01-20T17:05:34.777337+0200][412545][INFO] Iteration imputation: select_model_by_column: False, select_model_by_iteration: False\n",
      "[2022-01-20T17:05:34.783563+0200][412545][INFO] Iteration imputation: select_model_by_column: False, select_model_by_iteration: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airfoil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 17:05:37.297243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-20 17:05:37.297270: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-20 17:05:37.324127: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-20 17:05:37.324155: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:tensorflow:From /home/bcebere/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /home/bcebere/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_white\n"
     ]
    }
   ],
   "source": [
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from benchmark_imputation import ws_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "dispatcher = Parallel(n_jobs=2)\n",
    "\n",
    "output_dir = Path(\"extras_gain_of_function_results\")\n",
    "baseline_regressors = [\"linear_regression\", \"random_forest_regressor\"]\n",
    "\n",
    "def full_hyperimpute(): \n",
    "    return imputers.get(\"hyperimpute\", \n",
    "            optimizer = \"hyperband\",\n",
    "            select_lazy = False,\n",
    "        )\n",
    "\n",
    "def automl_constant_columns_change_iterations(): \n",
    "    return imputers.get(\"hyperimpute\", \n",
    "            optimizer = \"hyperband\",   \n",
    "            select_model_by_column = False,\n",
    "            select_model_by_iteration = True,\n",
    "            select_lazy = True,\n",
    "        )\n",
    "def automl_change_columns_constant_iterations(): \n",
    "    return imputers.get(\"hyperimpute\", \n",
    "            optimizer = \"hyperband\", \n",
    "            select_model_by_column = True,\n",
    "            select_model_by_iteration = False,\n",
    "            select_lazy = True,\n",
    "        )\n",
    "def automl_constant_columns_constant_iterations(): \n",
    "    return imputers.get(\"hyperimpute\", \n",
    "            optimizer = \"hyperband\",\n",
    "            select_model_by_column = False,\n",
    "            select_model_by_iteration = False,\n",
    "            select_lazy = True,\n",
    "        )\n",
    "\n",
    "def automl_use_only_lr(): \n",
    "    return imputers.get(\"hyperimpute\", \n",
    "            optimizer = \"hyperband\",\n",
    "            regression_seed = [\"linear_regression\"],\n",
    "            classifier_seed = [\"logistic_regression\"],\n",
    "            \n",
    "            select_model_by_column = False,\n",
    "            select_model_by_iteration = False,\n",
    "            select_lazy = True,\n",
    "        )\n",
    "\n",
    "def automl_use_only_rf(): \n",
    "    return imputers.get(\"hyperimpute\", \n",
    "            optimizer = \"hyperband\",\n",
    "            regression_seed = [\"random_forest_regressor\"],\n",
    "            classifier_seed = [\"random_forest\"],\n",
    "            \n",
    "            select_model_by_column = False,\n",
    "            select_model_by_iteration = False,\n",
    "            select_lazy = True,\n",
    "        )\n",
    "\n",
    "\n",
    "def automl_use_only_cb(): \n",
    "    return imputers.get(\"hyperimpute\", \n",
    "            optimizer = \"hyperband\",\n",
    "            regression_seed = [\"catboost_regressor\"],\n",
    "            classifier_seed = [\"catboost\"],\n",
    "                        \n",
    "            select_model_by_column = False,\n",
    "            select_model_by_iteration = False,\n",
    "            select_lazy = True,\n",
    "        )\n",
    "\n",
    "def no_automl_constant_columns_constant_iterations(): \n",
    "    return imputers.get(\"hyperimpute\", \n",
    "            optimizer = \"simple\",\n",
    "            select_model_by_column = False,\n",
    "            select_model_by_iteration = False,\n",
    "            select_lazy = True,\n",
    "        )\n",
    "\n",
    "evaluated_scenarios = {\n",
    "    \"Full HyperImpute\": full_hyperimpute(),\n",
    "    \"constant_columns_change_iterations\": automl_constant_columns_change_iterations(),\n",
    "    \"change_columns_constant_iterations\": automl_change_columns_constant_iterations(),\n",
    "    \"constant_columns_constant_iterations\": automl_constant_columns_constant_iterations(),\n",
    "    \"no_automl_constant_columns_constant_iterations\": no_automl_constant_columns_constant_iterations(),\n",
    "    \"seeds_only_lr\": automl_use_only_lr(),\n",
    "    \"seeds_only_rf\": automl_use_only_rf(),\n",
    "    \"seeds__only_cb\": automl_use_only_cb(),\n",
    "}\n",
    "\n",
    "def evaluate_dataset_gain(name: str, X_raw: pd.DataFrame, \n",
    "    scenario: str = \"MAR\",\n",
    "    missingness: float = 0.3,\n",
    "    debug: bool = True,\n",
    "):\n",
    "    imputation_scenarios = simulate_scenarios(X_raw, column_limit = 10)\n",
    "\n",
    "    ws_scores = []\n",
    "    rmse_scores = []\n",
    "    try:\n",
    "        x, x_miss, mask = imputation_scenarios[scenario][missingness]\n",
    "\n",
    "        for fun_scenario in evaluated_scenarios:\n",
    "            print(\"   evaluate \", name, fun_scenario)\n",
    "            model = evaluated_scenarios[fun_scenario]\n",
    "                \n",
    "            xt = model.fit_transform(x_miss.copy())\n",
    "                    \n",
    "            distribution_score = ws_score(xt, x)\n",
    "            rmse_score = RMSE(np.asarray(xt), np.asarray(x), np.asarray(mask))\n",
    "                \n",
    "            ws_scores.append(distribution_score)\n",
    "            rmse_scores.append(rmse_score)\n",
    "            \n",
    "    except BaseException as e:\n",
    "        print(\"scenario failed\", str(e))\n",
    "        raise e\n",
    "    return ws_scores, rmse_scores\n",
    "\n",
    "out_keys = [\"dataset\"] + list(evaluated_scenarios.keys())\n",
    "\n",
    "output_rmse_df = pd.DataFrame([], columns = out_keys)\n",
    "output_rmse_std_df = pd.DataFrame([], columns = out_keys)\n",
    "output_ws_df = pd.DataFrame([], columns = out_keys)\n",
    "output_ws_std_df = pd.DataFrame([], columns = out_keys)\n",
    "\n",
    "for dataset in raw_datasets:\n",
    "    try:\n",
    "        print(dataset)\n",
    "        df = raw_datasets[dataset]\n",
    "\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                df[col] = LabelEncoder().fit_transform(df[col])\n",
    "            \n",
    "        scenario = \"MAR\"\n",
    "        miss = 0.3\n",
    "        \n",
    "        local_ws_scores = []\n",
    "        local_rmse_scores = []\n",
    "        \n",
    "        bench_res = dispatcher(\n",
    "            delayed(evaluate_dataset_gain)(dataset, df, scenario, miss) for i in range(5))\n",
    "            \n",
    "            \n",
    "        for ws_res, rmse_res in bench_res:\n",
    "            local_ws_scores.append(ws_res)\n",
    "            local_rmse_scores.append(rmse_res)\n",
    "            \n",
    "        ws_scores_iters = []\n",
    "        ws_scores_iters_std = []\n",
    "        for scenario_res in np.array(local_ws_scores).T:\n",
    "            score = generate_score(scenario_res)\n",
    "            ws_scores_iters.append(score[0])\n",
    "            ws_scores_iters_std.append(score[1])\n",
    "        output_ws_df = output_ws_df.append(pd.DataFrame([[dataset] + ws_scores_iters], columns = out_keys))\n",
    "        output_ws_std_df = output_ws_std_df.append(pd.DataFrame([[dataset] + ws_scores_iters_std], columns = out_keys))\n",
    "              \n",
    "        rmse_scores_iters = []\n",
    "        rmse_scores_iters_std = []\n",
    "        for scenario_res in np.array(local_rmse_scores).T:\n",
    "            score = generate_score(scenario_res)\n",
    "            rmse_scores_iters.append(score[0])\n",
    "            rmse_scores_iters_std.append(score[1])\n",
    "            \n",
    "        output_rmse_df = output_rmse_df.append(pd.DataFrame([[dataset] + rmse_scores_iters], columns = out_keys))\n",
    "        output_rmse_std_df = output_rmse_std_df.append(pd.DataFrame([[dataset] + rmse_scores_iters_std], columns = out_keys))\n",
    "    except BaseException as e:\n",
    "        print(\"scenario failed\", dataset, e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b27b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"extras_gain_of_function_results\")\n",
    "\n",
    "output_rmse_df.to_csv(output_dir / \"rmse_eval.csv\", index = None)\n",
    "output_rmse_std_df.to_csv(output_dir / \"rmse_std_eval.csv\", index = None)\n",
    "\n",
    "output_rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c3a7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_dir = Path(\"extras_gain_of_function_results\")\n",
    "\n",
    "output_ws_df.to_csv(output_dir / \"ws_eval.csv\", index = None)\n",
    "output_ws_std_df.to_csv(output_dir / \"ws_std_eval.csv\", index = None)\n",
    "\n",
    "output_ws_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748662ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_std(mean_df, std_df):\n",
    "    merged = mean_df.copy()\n",
    "    \n",
    "    for r in range(merged.shape[0]):\n",
    "        minval = np.argmin(merged.iloc[r,:].values[1 : ]) + 1\n",
    "        for c in range(merged.shape[1]):\n",
    "            if isinstance(merged.iloc[r, c], str):\n",
    "                  continue\n",
    "            merged.iloc[r, c] = print_score((merged.iloc[r, c], std_df.iloc[r, c]))\n",
    "            \n",
    "            \n",
    "            if c == minval:\n",
    "                merged.iloc[r, c] = \"**\" + merged.iloc[r, c] + \"**\"\n",
    "\n",
    "    return merged\n",
    "\n",
    "res = plot_mean_std(output_rmse_df, output_rmse_std_df)\n",
    "\n",
    "rename_cols = {\n",
    "    \"no_automl_constant_columns_constant_iterations\": \"no_automl\",\n",
    "    \"constant_columns_change_iterations\": \"const_col_ch_iter\",\n",
    "    \"change_columns_constant_iterations\": \"ch_col_const_iter\",\n",
    "    \"constant_columns_constant_iterations\": \"const_col_const_iter\",\n",
    "    \"Full HyperImpute\": \"full\",\n",
    "}\n",
    "res.rename(columns = rename_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_std(output_ws_df, output_ws_std_df).rename(columns=rename_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb7282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b5fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
